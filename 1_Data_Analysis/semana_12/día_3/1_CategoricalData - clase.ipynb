{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0x9BSWIok-4C"
   },
   "source": [
    "# Categorical Values\n",
    "\n",
    "A categorical variable, as the name suggests, is used to represent categories or labels. For instance, a categorical variable could represent major cities in the world, the four seasons in a year, or the industry (oil, travel, technology) of a company. The number of category values is always finite in a real-world dataset. The values may be represented numerically. However, unlike other numeric variables, the values of a categorical variable cannot be ordered with respect to one another. (Oil is neither greater than nor less than travel as an industry type.) They are called nonordinal.\n",
    "\n",
    "A simple question can serve as litmus test for whether something should be a categorical variable: “Does it matter how different two values are, or only that they are different?” A stock price of 500 € is five times higher than a price of 100 €. So, stock price should be represented by a continuous numeric variable. The industry of the company (oil, travel, tech, etc.), on the other hand, should probably be categorical.\n",
    "\n",
    "Large categorical variables are particularly common in transactional records. For instance, many web services track users using an ID, which is a categorical variable with hundreds to hundreds of millions of values, depending on the number of unique users of the service. \n",
    "\n",
    "The IP address of an internet transaction is another example of a large categorical variable. They are categorical variables because, even though user IDs and IP addresses are numeric, their magnitude is usually not relevant to the task at hand. For instance, the IP address might be relevant when doing fraud detection on individual transactions—some IP addresses or subnets may generate more fraudulent transactions than others. But a subnet of 164.203.x.x is not inherently more fraudulent than 164.202.x.x; the numeric value of the subnet does not matter.\n",
    "\n",
    "The vocabulary of a document corpus can be interpreted as a large categorical variable, with the categories being unique words. It can be computationally expensive to represent so many distinct categories. If a category (e.g., word) appears multiple times in a data point (document), then we can represent it as a count, and represent all of the categories through their count statistics. \n",
    "\n",
    "This is called bin counting. We start this discussion with common representations of categorical variables, and eventually meander our way to a discussion of bin counting for large categorical variables, which are very common in modern datasets.\n",
    "\n",
    "# Encoding Categorical Variables\n",
    "\n",
    "The categories of a categorical variable are usually not numeric.1 For example, eye color can be “black,” “blue,” “brown,” etc. Thus, an encoding method is needed to turn these nonnumeric categories into numbers. It is tempting to simply assign an integer, say from 1 to k, to each of k possible categories—but the resulting values would be orderable against each other, which should not be permissible for categories. So, let’s look at some alternatives.\n",
    "One-Hot Encoding\n",
    "\n",
    "A better method is to use a group of bits. Each bit represents a possible category. If the variable cannot belong to multiple categories at once, then only one bit in the group can be “on.” This is called one-hot encoding, and it is implemented in scikit-learn as sklearn.preprocessing.OneHotEncoder. Each of the bits is a feature. Thus, a categorical variable with k possible categories is encoded as a feature vector of length k. Table 5-1 shows an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yeUyHEnAk-4D"
   },
   "source": [
    "![texto alternativo](https://drive.google.com/uc?id=1qL2klfmXws6LXfhgLD2WPLT544cr9BlT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lcxiSGpNk-4E"
   },
   "source": [
    "One-hot encoding is very simple to understand, but it uses one more bit than is strictly necessary. If we see that k–1 of the bits are 0, then the last bit must be 1 because the variable must take on one of the k values. Mathematically, one can write this constraint as “the sum of all bits must be equal to 1”:\n",
    "e 1 + e 2 + . . . + e k = 1\n",
    "\n",
    "Thus, we have a linear dependency on our hands. Linear dependent features, as we discovered in Chapter 4, are slightly annoying because they mean that the trained linear models will not be unique. Different linear combinations of the features can make the same predictions, so we would need to jump through extra hoops to understand the effect of a feature on the prediction.\n",
    "\n",
    "\n",
    "## Dummy Coding\n",
    "\n",
    "The problem with one-hot encoding is that it allows for k degrees of freedom, while the variable itself needs only k–1. Dummy coding2 removes the extra degree of freedom by using only k–1 features in the representation (see Table 5-2). One feature is thrown under the bus and represented by the vector of all zeros. This is known as the reference category. Dummy coding and one-hot encoding are both implemented in Pandas as pandas.get_dummies.\n",
    "Table 5-2. Dummy coding of a category of three cities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t72LvZ5-k-4E"
   },
   "source": [
    "The outcome of modeling with dummy coding is more interpretable than with one-hot encoding. This is easy to see in a simple linear regression problem. Suppose we have some data about apartment rental prices in three cities: San Francisco, New York, and Seattle (see Table 5-3).\n",
    "Table 5-3. Toy dataset of apartment prices in three cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gJwqnblZk-4F"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      City  Rent\n0       SF  3999\n1       SF  4000\n2       SF  4001\n3       NY  3499\n4       NY  3500\n5       NY  3501\n6  Seattle  2499\n7  Seattle  2500\n8  Seattle  2501",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>City</th>\n      <th>Rent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>SF</td>\n      <td>3999</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>SF</td>\n      <td>4000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>SF</td>\n      <td>4001</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>NY</td>\n      <td>3499</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>NY</td>\n      <td>3500</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>NY</td>\n      <td>3501</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>Seattle</td>\n      <td>2499</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>Seattle</td>\n      <td>2500</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>Seattle</td>\n      <td>2501</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "df = pd.DataFrame({'City':['SF','SF', 'SF', 'NY', 'NY', 'NY', 'Seattle', 'Seattle', 'Seattle'],\n",
    "'Rent':[3999, 4000, 4001, 3499, 3500, 3501, 2499, 2500, 2501]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cH6Wx51fk-4I",
    "outputId": "2051375c-1bbe-4bf1-d0fe-701ff687a2ca"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Rent  City_NY  City_SF  City_Seattle\n0  3999        0        1             0\n1  4000        0        1             0\n2  4001        0        1             0\n3  3499        1        0             0\n4  3500        1        0             0\n5  3501        1        0             0\n6  2499        0        0             1\n7  2500        0        0             1\n8  2501        0        0             1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rent</th>\n      <th>City_NY</th>\n      <th>City_SF</th>\n      <th>City_Seattle</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>3999</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>4000</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>4001</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3499</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>3500</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>3501</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>2499</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>2500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>2501</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "one_hot_df = pd.get_dummies(df, prefix='City')\n",
    "one_hot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AlRfNyUYk-4L",
    "outputId": "d8197e1a-1027-44d4-8a6c-ad8a668f756b"
   },
   "outputs": [],
   "source": [
    "lin_reg = linear_model.LinearRegression()\n",
    "#Ajusta a una linea los punto para generar una Regresión Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "lin_reg.fit(one_hot_df[[ 'City_NY', 'City_SF', 'City_Seattle']], one_hot_df[['Rent']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a92VojSVk-4O"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 166.66666667,  666.66666667, -833.33333333]])"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "lin_reg.coef_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iA6n0Sajk-4Q",
    "outputId": "a606e274-f3d6-473d-90fc-34c7dd1c9af5"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([3333.33333333])"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "lin_reg.intercept_ #Termino continuo = constante de Rent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kk4a6Erkk-4X"
   },
   "outputs": [],
   "source": [
    "# One-hot encoding weights + intercept\n",
    "w1 = lin_reg.coef_\n",
    " = lin_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RllE2o72k-4Z",
    "outputId": "98f3aa19-cc17-4c0e-df3f-90cef929d29a"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3333.3333333333335"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "df['Rent'].mean() #Vale lo mismo que el intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jUBSw1Myk-4b",
    "outputId": "97055154-1091-4a5b-f66d-66b785b36379"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Rent  City_SF  City_Seattle\n0  3999        1             0\n1  4000        1             0\n2  4001        1             0\n3  3499        0             0\n4  3500        0             0\n5  3501        0             0\n6  2499        0             1\n7  2500        0             1\n8  2501        0             1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rent</th>\n      <th>City_SF</th>\n      <th>City_Seattle</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>3999</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>4000</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>4001</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3499</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>3500</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>3501</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>2499</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>2500</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>2501</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "#Ahora con Dummy\n",
    "dummy_df = pd.get_dummies(df, prefix=['City'], drop_first=True)\n",
    "dummy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r4-abR0ak-4d",
    "outputId": "bc442e82-8bce-4a56-ec12-a127235e0f43"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "lin_reg.fit(dummy_df[['City_SF', 'City_Seattle']], dummy_df['Rent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LMmIO989k-4g",
    "outputId": "88abca92-1b84-418c-e680-f22dcec61cb2"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([  500., -1000.])"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "lin_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c1eJC3XUk-4i",
    "outputId": "a8d0f8c2-4ad0-47c9-c845-8180bfa88140"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3500.0"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "lin_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6TmH_GCbk-4l"
   },
   "outputs": [],
   "source": [
    "# Dummy coding weights + intercept\n",
    "w2 = lin_reg.coef_\n",
    "b2 = lin_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8zdNV5hok-4n"
   },
   "outputs": [],
   "source": [
    "effect_df = dummy_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3wRvlap4k-4p",
    "outputId": "2a566d2b-f4ca-493a-d30c-297383d09c74"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Rent  City_SF  City_Seattle\n0  3999        1             0\n1  4000        1             0\n2  4001        1             0\n3  3499      255           255\n4  3500      255           255\n5  3501      255           255\n6  2499        0             1\n7  2500        0             1\n8  2501        0             1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rent</th>\n      <th>City_SF</th>\n      <th>City_Seattle</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>3999</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>4000</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>4001</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3499</td>\n      <td>255</td>\n      <td>255</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>3500</td>\n      <td>255</td>\n      <td>255</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>3501</td>\n      <td>255</td>\n      <td>255</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>2499</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>2500</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>2501</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "effect_df.loc[3:5,['City_SF', 'City_Seattle']] = -1\n",
    "effect_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sul0ot6tk-4s",
    "outputId": "b2537e81-f0f7-4ba8-84c8-b2e6d7d1c7b9"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "lin_reg.fit(effect_df[['City_SF', 'City_Seattle']], effect_df['Rent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wOXcBgiek-4u",
    "outputId": "78c66971-6c07-49ce-feb1-780e897ced3a"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3249.508840864413"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "lin_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xzhHG57hk-4w"
   },
   "outputs": [],
   "source": [
    "\n",
    "# illustration of rental price in cities\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas.util.testing as tm\n",
    "sns.set(style=\"whitegrid\", font_scale=1.4, color_codes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LDninYsUk-4x",
    "outputId": "7b149c52-87b1-4846-b479-d02e5ba535d9"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;Figure size 432x288 with 1 Axes&gt;",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"275.189531pt\" version=\"1.1\" viewBox=\"0 0 412.3195 275.189531\" width=\"412.3195pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 275.189531 \r\nL 412.3195 275.189531 \r\nL 412.3195 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 70.3195 224.64 \r\nL 405.1195 224.64 \r\nL 405.1195 7.2 \r\nL 70.3195 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"text_1\">\r\n      <!-- SF -->\r\n      <defs>\r\n       <path d=\"M 4.5 23 \r\nL 13.421875 23.78125 \r\nQ 14.0625 18.40625 16.375 14.96875 \r\nQ 18.703125 11.53125 23.578125 9.40625 \r\nQ 28.46875 7.28125 34.578125 7.28125 \r\nQ 39.984375 7.28125 44.140625 8.890625 \r\nQ 48.296875 10.5 50.3125 13.296875 \r\nQ 52.34375 16.109375 52.34375 19.4375 \r\nQ 52.34375 22.796875 50.390625 25.3125 \r\nQ 48.4375 27.828125 43.953125 29.546875 \r\nQ 41.0625 30.671875 31.203125 33.03125 \r\nQ 21.34375 35.40625 17.390625 37.5 \r\nQ 12.25 40.1875 9.734375 44.15625 \r\nQ 7.234375 48.140625 7.234375 53.078125 \r\nQ 7.234375 58.5 10.296875 63.203125 \r\nQ 13.375 67.921875 19.28125 70.359375 \r\nQ 25.203125 72.796875 32.421875 72.796875 \r\nQ 40.375 72.796875 46.453125 70.234375 \r\nQ 52.546875 67.671875 55.8125 62.6875 \r\nQ 59.078125 57.71875 59.328125 51.421875 \r\nL 50.25 50.734375 \r\nQ 49.515625 57.515625 45.28125 60.984375 \r\nQ 41.0625 64.453125 32.8125 64.453125 \r\nQ 24.21875 64.453125 20.28125 61.296875 \r\nQ 16.359375 58.15625 16.359375 53.71875 \r\nQ 16.359375 49.859375 19.140625 47.359375 \r\nQ 21.875 44.875 33.421875 42.265625 \r\nQ 44.96875 39.65625 49.265625 37.703125 \r\nQ 55.515625 34.8125 58.484375 30.390625 \r\nQ 61.46875 25.984375 61.46875 20.21875 \r\nQ 61.46875 14.5 58.203125 9.4375 \r\nQ 54.9375 4.390625 48.796875 1.578125 \r\nQ 42.671875 -1.21875 35.015625 -1.21875 \r\nQ 25.296875 -1.21875 18.71875 1.609375 \r\nQ 12.15625 4.4375 8.421875 10.125 \r\nQ 4.6875 15.828125 4.5 23 \r\nz\r\n\" id=\"ArialMT-83\"/>\r\n       <path d=\"M 8.203125 0 \r\nL 8.203125 71.578125 \r\nL 56.5 71.578125 \r\nL 56.5 63.140625 \r\nL 17.671875 63.140625 \r\nL 17.671875 40.96875 \r\nL 51.265625 40.96875 \r\nL 51.265625 32.515625 \r\nL 17.671875 32.515625 \r\nL 17.671875 0 \r\nz\r\n\" id=\"ArialMT-70\"/>\r\n      </defs>\r\n      <g style=\"fill:#262626;\" transform=\"translate(116.280344 245.163031)scale(0.154 -0.154)\">\r\n       <use xlink:href=\"#ArialMT-83\"/>\r\n       <use x=\"66.699219\" xlink:href=\"#ArialMT-70\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"text_2\">\r\n      <!-- NY -->\r\n      <defs>\r\n       <path d=\"M 7.625 0 \r\nL 7.625 71.578125 \r\nL 17.328125 71.578125 \r\nL 54.9375 15.375 \r\nL 54.9375 71.578125 \r\nL 64.015625 71.578125 \r\nL 64.015625 0 \r\nL 54.296875 0 \r\nL 16.703125 56.25 \r\nL 16.703125 0 \r\nz\r\n\" id=\"ArialMT-78\"/>\r\n       <path d=\"M 27.875 0 \r\nL 27.875 30.328125 \r\nL 0.296875 71.578125 \r\nL 11.8125 71.578125 \r\nL 25.921875 50 \r\nQ 29.828125 43.953125 33.203125 37.890625 \r\nQ 36.421875 43.5 41.015625 50.53125 \r\nL 54.890625 71.578125 \r\nL 65.921875 71.578125 \r\nL 37.359375 30.328125 \r\nL 37.359375 0 \r\nz\r\n\" id=\"ArialMT-89\"/>\r\n      </defs>\r\n      <g style=\"fill:#262626;\" transform=\"translate(227.022516 245.163031)scale(0.154 -0.154)\">\r\n       <use xlink:href=\"#ArialMT-78\"/>\r\n       <use x=\"72.216797\" xlink:href=\"#ArialMT-89\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"text_3\">\r\n      <!-- Seattle -->\r\n      <defs>\r\n       <path d=\"M 42.09375 16.703125 \r\nL 51.171875 15.578125 \r\nQ 49.03125 7.625 43.21875 3.21875 \r\nQ 37.40625 -1.171875 28.375 -1.171875 \r\nQ 17 -1.171875 10.328125 5.828125 \r\nQ 3.65625 12.84375 3.65625 25.484375 \r\nQ 3.65625 38.578125 10.390625 45.796875 \r\nQ 17.140625 53.03125 27.875 53.03125 \r\nQ 38.28125 53.03125 44.875 45.953125 \r\nQ 51.46875 38.875 51.46875 26.03125 \r\nQ 51.46875 25.25 51.421875 23.6875 \r\nL 12.75 23.6875 \r\nQ 13.234375 15.140625 17.578125 10.59375 \r\nQ 21.921875 6.0625 28.421875 6.0625 \r\nQ 33.25 6.0625 36.671875 8.59375 \r\nQ 40.09375 11.140625 42.09375 16.703125 \r\nz\r\nM 13.234375 30.90625 \r\nL 42.1875 30.90625 \r\nQ 41.609375 37.453125 38.875 40.71875 \r\nQ 34.671875 45.796875 27.984375 45.796875 \r\nQ 21.921875 45.796875 17.796875 41.75 \r\nQ 13.671875 37.703125 13.234375 30.90625 \r\nz\r\n\" id=\"ArialMT-101\"/>\r\n       <path d=\"M 40.4375 6.390625 \r\nQ 35.546875 2.25 31.03125 0.53125 \r\nQ 26.515625 -1.171875 21.34375 -1.171875 \r\nQ 12.796875 -1.171875 8.203125 3 \r\nQ 3.609375 7.171875 3.609375 13.671875 \r\nQ 3.609375 17.484375 5.34375 20.625 \r\nQ 7.078125 23.78125 9.890625 25.6875 \r\nQ 12.703125 27.59375 16.21875 28.5625 \r\nQ 18.796875 29.25 24.03125 29.890625 \r\nQ 34.671875 31.15625 39.703125 32.90625 \r\nQ 39.75 34.71875 39.75 35.203125 \r\nQ 39.75 40.578125 37.25 42.78125 \r\nQ 33.890625 45.75 27.25 45.75 \r\nQ 21.046875 45.75 18.09375 43.578125 \r\nQ 15.140625 41.40625 13.71875 35.890625 \r\nL 5.125 37.0625 \r\nQ 6.296875 42.578125 8.984375 45.96875 \r\nQ 11.671875 49.359375 16.75 51.1875 \r\nQ 21.828125 53.03125 28.515625 53.03125 \r\nQ 35.15625 53.03125 39.296875 51.46875 \r\nQ 43.453125 49.90625 45.40625 47.53125 \r\nQ 47.359375 45.171875 48.140625 41.546875 \r\nQ 48.578125 39.3125 48.578125 33.453125 \r\nL 48.578125 21.734375 \r\nQ 48.578125 9.46875 49.140625 6.21875 \r\nQ 49.703125 2.984375 51.375 0 \r\nL 42.1875 0 \r\nQ 40.828125 2.734375 40.4375 6.390625 \r\nz\r\nM 39.703125 26.03125 \r\nQ 34.90625 24.078125 25.34375 22.703125 \r\nQ 19.921875 21.921875 17.671875 20.9375 \r\nQ 15.4375 19.96875 14.203125 18.09375 \r\nQ 12.984375 16.21875 12.984375 13.921875 \r\nQ 12.984375 10.40625 15.640625 8.0625 \r\nQ 18.3125 5.71875 23.4375 5.71875 \r\nQ 28.515625 5.71875 32.46875 7.9375 \r\nQ 36.421875 10.15625 38.28125 14.015625 \r\nQ 39.703125 17 39.703125 22.796875 \r\nz\r\n\" id=\"ArialMT-97\"/>\r\n       <path d=\"M 25.78125 7.859375 \r\nL 27.046875 0.09375 \r\nQ 23.34375 -0.6875 20.40625 -0.6875 \r\nQ 15.625 -0.6875 12.984375 0.828125 \r\nQ 10.359375 2.34375 9.28125 4.8125 \r\nQ 8.203125 7.28125 8.203125 15.1875 \r\nL 8.203125 45.015625 \r\nL 1.765625 45.015625 \r\nL 1.765625 51.859375 \r\nL 8.203125 51.859375 \r\nL 8.203125 64.703125 \r\nL 16.9375 69.96875 \r\nL 16.9375 51.859375 \r\nL 25.78125 51.859375 \r\nL 25.78125 45.015625 \r\nL 16.9375 45.015625 \r\nL 16.9375 14.703125 \r\nQ 16.9375 10.9375 17.40625 9.859375 \r\nQ 17.875 8.796875 18.921875 8.15625 \r\nQ 19.96875 7.515625 21.921875 7.515625 \r\nQ 23.390625 7.515625 25.78125 7.859375 \r\nz\r\n\" id=\"ArialMT-116\"/>\r\n       <path d=\"M 6.390625 0 \r\nL 6.390625 71.578125 \r\nL 15.1875 71.578125 \r\nL 15.1875 0 \r\nz\r\n\" id=\"ArialMT-108\"/>\r\n      </defs>\r\n      <g style=\"fill:#262626;\" transform=\"translate(325.348437 245.163031)scale(0.154 -0.154)\">\r\n       <use xlink:href=\"#ArialMT-83\"/>\r\n       <use x=\"66.699219\" xlink:href=\"#ArialMT-101\"/>\r\n       <use x=\"122.314453\" xlink:href=\"#ArialMT-97\"/>\r\n       <use x=\"177.929688\" xlink:href=\"#ArialMT-116\"/>\r\n       <use x=\"205.712891\" xlink:href=\"#ArialMT-116\"/>\r\n       <use x=\"233.496094\" xlink:href=\"#ArialMT-108\"/>\r\n       <use x=\"255.712891\" xlink:href=\"#ArialMT-101\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_4\">\r\n     <!-- City -->\r\n     <defs>\r\n      <path d=\"M 58.796875 25.09375 \r\nL 68.265625 22.703125 \r\nQ 65.28125 11.03125 57.546875 4.90625 \r\nQ 49.8125 -1.21875 38.625 -1.21875 \r\nQ 27.046875 -1.21875 19.796875 3.484375 \r\nQ 12.546875 8.203125 8.765625 17.140625 \r\nQ 4.984375 26.078125 4.984375 36.328125 \r\nQ 4.984375 47.515625 9.25 55.828125 \r\nQ 13.53125 64.15625 21.40625 68.46875 \r\nQ 29.296875 72.796875 38.765625 72.796875 \r\nQ 49.515625 72.796875 56.828125 67.328125 \r\nQ 64.15625 61.859375 67.046875 51.953125 \r\nL 57.71875 49.75 \r\nQ 55.21875 57.5625 50.484375 61.125 \r\nQ 45.75 64.703125 38.578125 64.703125 \r\nQ 30.328125 64.703125 24.78125 60.734375 \r\nQ 19.234375 56.78125 16.984375 50.109375 \r\nQ 14.75 43.453125 14.75 36.375 \r\nQ 14.75 27.25 17.40625 20.4375 \r\nQ 20.0625 13.625 25.671875 10.25 \r\nQ 31.296875 6.890625 37.84375 6.890625 \r\nQ 45.796875 6.890625 51.3125 11.46875 \r\nQ 56.84375 16.0625 58.796875 25.09375 \r\nz\r\n\" id=\"ArialMT-67\"/>\r\n      <path d=\"M 6.640625 61.46875 \r\nL 6.640625 71.578125 \r\nL 15.4375 71.578125 \r\nL 15.4375 61.46875 \r\nz\r\nM 6.640625 0 \r\nL 6.640625 51.859375 \r\nL 15.4375 51.859375 \r\nL 15.4375 0 \r\nz\r\n\" id=\"ArialMT-105\"/>\r\n      <path d=\"M 6.203125 -19.96875 \r\nL 5.21875 -11.71875 \r\nQ 8.109375 -12.5 10.25 -12.5 \r\nQ 13.1875 -12.5 14.9375 -11.515625 \r\nQ 16.703125 -10.546875 17.828125 -8.796875 \r\nQ 18.65625 -7.46875 20.515625 -2.25 \r\nQ 20.75 -1.515625 21.296875 -0.09375 \r\nL 1.609375 51.859375 \r\nL 11.078125 51.859375 \r\nL 21.875 21.828125 \r\nQ 23.96875 16.109375 25.640625 9.8125 \r\nQ 27.15625 15.875 29.25 21.625 \r\nL 40.328125 51.859375 \r\nL 49.125 51.859375 \r\nL 29.390625 -0.875 \r\nQ 26.21875 -9.421875 24.46875 -12.640625 \r\nQ 22.125 -17 19.09375 -19.015625 \r\nQ 16.0625 -21.046875 11.859375 -21.046875 \r\nQ 9.328125 -21.046875 6.203125 -19.96875 \r\nz\r\n\" id=\"ArialMT-121\"/>\r\n     </defs>\r\n     <g style=\"fill:#262626;\" transform=\"translate(223.253125 264.453656)scale(0.168 -0.168)\">\r\n      <use xlink:href=\"#ArialMT-67\"/>\r\n      <use x=\"72.216797\" xlink:href=\"#ArialMT-105\"/>\r\n      <use x=\"94.433594\" xlink:href=\"#ArialMT-116\"/>\r\n      <use x=\"122.216797\" xlink:href=\"#ArialMT-121\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_1\">\r\n      <path clip-path=\"url(#pe65df73cd0)\" d=\"M 70.3195 213.793222 \r\nL 405.1195 213.793222 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 2500 -->\r\n      <defs>\r\n       <path d=\"M 50.34375 8.453125 \r\nL 50.34375 0 \r\nL 3.03125 0 \r\nQ 2.9375 3.171875 4.046875 6.109375 \r\nQ 5.859375 10.9375 9.828125 15.625 \r\nQ 13.8125 20.3125 21.34375 26.46875 \r\nQ 33.015625 36.03125 37.109375 41.625 \r\nQ 41.21875 47.21875 41.21875 52.203125 \r\nQ 41.21875 57.421875 37.46875 61 \r\nQ 33.734375 64.59375 27.734375 64.59375 \r\nQ 21.390625 64.59375 17.578125 60.78125 \r\nQ 13.765625 56.984375 13.71875 50.25 \r\nL 4.6875 51.171875 \r\nQ 5.609375 61.28125 11.65625 66.578125 \r\nQ 17.71875 71.875 27.9375 71.875 \r\nQ 38.234375 71.875 44.234375 66.15625 \r\nQ 50.25 60.453125 50.25 52 \r\nQ 50.25 47.703125 48.484375 43.546875 \r\nQ 46.734375 39.40625 42.65625 34.8125 \r\nQ 38.578125 30.21875 29.109375 22.21875 \r\nQ 21.1875 15.578125 18.9375 13.203125 \r\nQ 16.703125 10.84375 15.234375 8.453125 \r\nz\r\n\" id=\"ArialMT-50\"/>\r\n       <path d=\"M 4.15625 18.75 \r\nL 13.375 19.53125 \r\nQ 14.40625 12.796875 18.140625 9.390625 \r\nQ 21.875 6 27.15625 6 \r\nQ 33.5 6 37.890625 10.78125 \r\nQ 42.28125 15.578125 42.28125 23.484375 \r\nQ 42.28125 31 38.0625 35.34375 \r\nQ 33.84375 39.703125 27 39.703125 \r\nQ 22.75 39.703125 19.328125 37.765625 \r\nQ 15.921875 35.84375 13.96875 32.765625 \r\nL 5.71875 33.84375 \r\nL 12.640625 70.609375 \r\nL 48.25 70.609375 \r\nL 48.25 62.203125 \r\nL 19.671875 62.203125 \r\nL 15.828125 42.96875 \r\nQ 22.265625 47.46875 29.34375 47.46875 \r\nQ 38.71875 47.46875 45.15625 40.96875 \r\nQ 51.609375 34.46875 51.609375 24.265625 \r\nQ 51.609375 14.546875 45.953125 7.46875 \r\nQ 39.0625 -1.21875 27.15625 -1.21875 \r\nQ 17.390625 -1.21875 11.203125 4.25 \r\nQ 5.03125 9.71875 4.15625 18.75 \r\nz\r\n\" id=\"ArialMT-53\"/>\r\n       <path d=\"M 4.15625 35.296875 \r\nQ 4.15625 48 6.765625 55.734375 \r\nQ 9.375 63.484375 14.515625 67.671875 \r\nQ 19.671875 71.875 27.484375 71.875 \r\nQ 33.25 71.875 37.59375 69.546875 \r\nQ 41.9375 67.234375 44.765625 62.859375 \r\nQ 47.609375 58.5 49.21875 52.21875 \r\nQ 50.828125 45.953125 50.828125 35.296875 \r\nQ 50.828125 22.703125 48.234375 14.96875 \r\nQ 45.65625 7.234375 40.5 3 \r\nQ 35.359375 -1.21875 27.484375 -1.21875 \r\nQ 17.140625 -1.21875 11.234375 6.203125 \r\nQ 4.15625 15.140625 4.15625 35.296875 \r\nz\r\nM 13.1875 35.296875 \r\nQ 13.1875 17.671875 17.3125 11.828125 \r\nQ 21.4375 6 27.484375 6 \r\nQ 33.546875 6 37.671875 11.859375 \r\nQ 41.796875 17.71875 41.796875 35.296875 \r\nQ 41.796875 52.984375 37.671875 58.78125 \r\nQ 33.546875 64.59375 27.390625 64.59375 \r\nQ 21.34375 64.59375 17.71875 59.46875 \r\nQ 13.1875 52.9375 13.1875 35.296875 \r\nz\r\n\" id=\"ArialMT-48\"/>\r\n      </defs>\r\n      <g style=\"fill:#262626;\" transform=\"translate(26.564125 219.304737)scale(0.154 -0.154)\">\r\n       <use xlink:href=\"#ArialMT-50\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-53\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-48\"/>\r\n       <use x=\"166.845703\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_2\">\r\n      <path clip-path=\"url(#pe65df73cd0)\" d=\"M 70.3195 181.030384 \r\nL 405.1195 181.030384 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 2750 -->\r\n      <defs>\r\n       <path d=\"M 4.734375 62.203125 \r\nL 4.734375 70.65625 \r\nL 51.078125 70.65625 \r\nL 51.078125 63.8125 \r\nQ 44.234375 56.546875 37.515625 44.484375 \r\nQ 30.8125 32.421875 27.15625 19.671875 \r\nQ 24.515625 10.6875 23.78125 0 \r\nL 14.75 0 \r\nQ 14.890625 8.453125 18.0625 20.40625 \r\nQ 21.234375 32.375 27.171875 43.484375 \r\nQ 33.109375 54.59375 39.796875 62.203125 \r\nz\r\n\" id=\"ArialMT-55\"/>\r\n      </defs>\r\n      <g style=\"fill:#262626;\" transform=\"translate(26.564125 186.5419)scale(0.154 -0.154)\">\r\n       <use xlink:href=\"#ArialMT-50\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-55\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-53\"/>\r\n       <use x=\"166.845703\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_3\">\r\n      <path clip-path=\"url(#pe65df73cd0)\" d=\"M 70.3195 148.267546 \r\nL 405.1195 148.267546 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 3000 -->\r\n      <defs>\r\n       <path d=\"M 4.203125 18.890625 \r\nL 12.984375 20.0625 \r\nQ 14.5 12.59375 18.140625 9.296875 \r\nQ 21.78125 6 27 6 \r\nQ 33.203125 6 37.46875 10.296875 \r\nQ 41.75 14.59375 41.75 20.953125 \r\nQ 41.75 27 37.796875 30.921875 \r\nQ 33.84375 34.859375 27.734375 34.859375 \r\nQ 25.25 34.859375 21.53125 33.890625 \r\nL 22.515625 41.609375 \r\nQ 23.390625 41.5 23.921875 41.5 \r\nQ 29.546875 41.5 34.03125 44.421875 \r\nQ 38.53125 47.359375 38.53125 53.46875 \r\nQ 38.53125 58.296875 35.25 61.46875 \r\nQ 31.984375 64.65625 26.8125 64.65625 \r\nQ 21.6875 64.65625 18.265625 61.421875 \r\nQ 14.84375 58.203125 13.875 51.765625 \r\nL 5.078125 53.328125 \r\nQ 6.6875 62.15625 12.390625 67.015625 \r\nQ 18.109375 71.875 26.609375 71.875 \r\nQ 32.46875 71.875 37.390625 69.359375 \r\nQ 42.328125 66.84375 44.9375 62.5 \r\nQ 47.5625 58.15625 47.5625 53.265625 \r\nQ 47.5625 48.640625 45.0625 44.828125 \r\nQ 42.578125 41.015625 37.703125 38.765625 \r\nQ 44.046875 37.3125 47.5625 32.6875 \r\nQ 51.078125 28.078125 51.078125 21.140625 \r\nQ 51.078125 11.765625 44.234375 5.25 \r\nQ 37.40625 -1.265625 26.953125 -1.265625 \r\nQ 17.53125 -1.265625 11.296875 4.34375 \r\nQ 5.078125 9.96875 4.203125 18.890625 \r\nz\r\n\" id=\"ArialMT-51\"/>\r\n      </defs>\r\n      <g style=\"fill:#262626;\" transform=\"translate(26.564125 153.779062)scale(0.154 -0.154)\">\r\n       <use xlink:href=\"#ArialMT-51\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-48\"/>\r\n       <use x=\"166.845703\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_4\">\r\n      <path clip-path=\"url(#pe65df73cd0)\" d=\"M 70.3195 115.504708 \r\nL 405.1195 115.504708 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 3250 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(26.564125 121.016224)scale(0.154 -0.154)\">\r\n       <use xlink:href=\"#ArialMT-51\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-50\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-53\"/>\r\n       <use x=\"166.845703\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_5\">\r\n      <path clip-path=\"url(#pe65df73cd0)\" d=\"M 70.3195 82.74187 \r\nL 405.1195 82.74187 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 3500 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(26.564125 88.253386)scale(0.154 -0.154)\">\r\n       <use xlink:href=\"#ArialMT-51\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-53\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-48\"/>\r\n       <use x=\"166.845703\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_6\">\r\n      <path clip-path=\"url(#pe65df73cd0)\" d=\"M 70.3195 49.979032 \r\nL 405.1195 49.979032 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 3750 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(26.564125 55.490548)scale(0.154 -0.154)\">\r\n       <use xlink:href=\"#ArialMT-51\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-55\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-53\"/>\r\n       <use x=\"166.845703\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_7\">\r\n      <path clip-path=\"url(#pe65df73cd0)\" d=\"M 70.3195 17.216194 \r\nL 405.1195 17.216194 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 4000 -->\r\n      <defs>\r\n       <path d=\"M 32.328125 0 \r\nL 32.328125 17.140625 \r\nL 1.265625 17.140625 \r\nL 1.265625 25.203125 \r\nL 33.9375 71.578125 \r\nL 41.109375 71.578125 \r\nL 41.109375 25.203125 \r\nL 50.78125 25.203125 \r\nL 50.78125 17.140625 \r\nL 41.109375 17.140625 \r\nL 41.109375 0 \r\nz\r\nM 32.328125 25.203125 \r\nL 32.328125 57.46875 \r\nL 9.90625 25.203125 \r\nz\r\n\" id=\"ArialMT-52\"/>\r\n      </defs>\r\n      <g style=\"fill:#262626;\" transform=\"translate(26.564125 22.72771)scale(0.154 -0.154)\">\r\n       <use xlink:href=\"#ArialMT-52\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-48\"/>\r\n       <use x=\"166.845703\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_12\">\r\n     <!-- Rent -->\r\n     <defs>\r\n      <path d=\"M 7.859375 0 \r\nL 7.859375 71.578125 \r\nL 39.59375 71.578125 \r\nQ 49.171875 71.578125 54.140625 69.640625 \r\nQ 59.125 67.71875 62.109375 62.828125 \r\nQ 65.09375 57.953125 65.09375 52.046875 \r\nQ 65.09375 44.4375 60.15625 39.203125 \r\nQ 55.21875 33.984375 44.921875 32.5625 \r\nQ 48.6875 30.765625 50.640625 29 \r\nQ 54.78125 25.203125 58.5 19.484375 \r\nL 70.953125 0 \r\nL 59.03125 0 \r\nL 49.5625 14.890625 \r\nQ 45.40625 21.34375 42.71875 24.75 \r\nQ 40.046875 28.171875 37.921875 29.53125 \r\nQ 35.796875 30.90625 33.59375 31.453125 \r\nQ 31.984375 31.78125 28.328125 31.78125 \r\nL 17.328125 31.78125 \r\nL 17.328125 0 \r\nz\r\nM 17.328125 39.984375 \r\nL 37.703125 39.984375 \r\nQ 44.1875 39.984375 47.84375 41.328125 \r\nQ 51.515625 42.671875 53.421875 45.625 \r\nQ 55.328125 48.578125 55.328125 52.046875 \r\nQ 55.328125 57.125 51.640625 60.390625 \r\nQ 47.953125 63.671875 39.984375 63.671875 \r\nL 17.328125 63.671875 \r\nz\r\n\" id=\"ArialMT-82\"/>\r\n      <path d=\"M 6.59375 0 \r\nL 6.59375 51.859375 \r\nL 14.5 51.859375 \r\nL 14.5 44.484375 \r\nQ 20.21875 53.03125 31 53.03125 \r\nQ 35.6875 53.03125 39.625 51.34375 \r\nQ 43.5625 49.65625 45.515625 46.921875 \r\nQ 47.46875 44.1875 48.25 40.4375 \r\nQ 48.734375 37.984375 48.734375 31.890625 \r\nL 48.734375 0 \r\nL 39.9375 0 \r\nL 39.9375 31.546875 \r\nQ 39.9375 36.921875 38.90625 39.578125 \r\nQ 37.890625 42.234375 35.28125 43.8125 \r\nQ 32.671875 45.40625 29.15625 45.40625 \r\nQ 23.53125 45.40625 19.453125 41.84375 \r\nQ 15.375 38.28125 15.375 28.328125 \r\nL 15.375 0 \r\nz\r\n\" id=\"ArialMT-110\"/>\r\n     </defs>\r\n     <g style=\"fill:#262626;\" transform=\"translate(19.225125 133.662375)rotate(-90)scale(0.168 -0.168)\">\r\n      <use xlink:href=\"#ArialMT-82\"/>\r\n      <use x=\"72.216797\" xlink:href=\"#ArialMT-101\"/>\r\n      <use x=\"127.832031\" xlink:href=\"#ArialMT-110\"/>\r\n      <use x=\"183.447266\" xlink:href=\"#ArialMT-116\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 70.3195 224.64 \r\nL 70.3195 7.2 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 405.1195 224.64 \r\nL 405.1195 7.2 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 70.3195 224.64 \r\nL 405.1195 224.64 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 70.3195 7.2 \r\nL 405.1195 7.2 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"PathCollection_1\">\r\n    <defs>\r\n     <path d=\"M 0 2.5 \r\nC 0.663008 2.5 1.29895 2.236584 1.767767 1.767767 \r\nC 2.236584 1.29895 2.5 0.663008 2.5 0 \r\nC 2.5 -0.663008 2.236584 -1.29895 1.767767 -1.767767 \r\nC 1.29895 -2.236584 0.663008 -2.5 0 -2.5 \r\nC -0.663008 -2.5 -1.29895 -2.236584 -1.767767 -1.767767 \r\nC -2.236584 -1.29895 -2.5 -0.663008 -2.5 0 \r\nC -2.5 0.663008 -2.236584 1.29895 -1.767767 1.767767 \r\nC -1.29895 2.236584 -0.663008 2.5 0 2.5 \r\nz\r\n\" id=\"C0_0_8ad1b7bc7b\"/>\r\n    </defs>\r\n    <g clip-path=\"url(#pe65df73cd0)\">\r\n     <use style=\"fill:#4c72b0;\" x=\"126.1195\" xlink:href=\"#C0_0_8ad1b7bc7b\" y=\"17.347246\"/>\r\n    </g>\r\n    <g clip-path=\"url(#pe65df73cd0)\">\r\n     <use style=\"fill:#4c72b0;\" x=\"120.871304\" xlink:href=\"#C0_0_8ad1b7bc7b\" y=\"17.216194\"/>\r\n    </g>\r\n    <g clip-path=\"url(#pe65df73cd0)\">\r\n     <use style=\"fill:#4c72b0;\" x=\"131.362282\" xlink:href=\"#C0_0_8ad1b7bc7b\" y=\"17.085143\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"PathCollection_2\">\r\n    <defs>\r\n     <path d=\"M 0 2.5 \r\nC 0.663008 2.5 1.29895 2.236584 1.767767 1.767767 \r\nC 2.236584 1.29895 2.5 0.663008 2.5 0 \r\nC 2.5 -0.663008 2.236584 -1.29895 1.767767 -1.767767 \r\nC 1.29895 -2.236584 0.663008 -2.5 0 -2.5 \r\nC -0.663008 -2.5 -1.29895 -2.236584 -1.767767 -1.767767 \r\nC -2.236584 -1.29895 -2.5 -0.663008 -2.5 0 \r\nC -2.5 0.663008 -2.236584 1.29895 -1.767767 1.767767 \r\nC -1.29895 2.236584 -0.663008 2.5 0 2.5 \r\nz\r\n\" id=\"C1_0_bbfa08d910\"/>\r\n    </defs>\r\n    <g clip-path=\"url(#pe65df73cd0)\">\r\n     <use style=\"fill:#dd8452;\" x=\"237.7195\" xlink:href=\"#C1_0_bbfa08d910\" y=\"82.872922\"/>\r\n    </g>\r\n    <g clip-path=\"url(#pe65df73cd0)\">\r\n     <use style=\"fill:#dd8452;\" x=\"232.471304\" xlink:href=\"#C1_0_bbfa08d910\" y=\"82.74187\"/>\r\n    </g>\r\n    <g clip-path=\"url(#pe65df73cd0)\">\r\n     <use style=\"fill:#dd8452;\" x=\"242.962282\" xlink:href=\"#C1_0_bbfa08d910\" y=\"82.610819\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"PathCollection_3\">\r\n    <defs>\r\n     <path d=\"M 0 2.5 \r\nC 0.663008 2.5 1.29895 2.236584 1.767767 1.767767 \r\nC 2.236584 1.29895 2.5 0.663008 2.5 0 \r\nC 2.5 -0.663008 2.236584 -1.29895 1.767767 -1.767767 \r\nC 1.29895 -2.236584 0.663008 -2.5 0 -2.5 \r\nC -0.663008 -2.5 -1.29895 -2.236584 -1.767767 -1.767767 \r\nC -2.236584 -1.29895 -2.5 -0.663008 -2.5 0 \r\nC -2.5 0.663008 -2.236584 1.29895 -1.767767 1.767767 \r\nC -1.29895 2.236584 -0.663008 2.5 0 2.5 \r\nz\r\n\" id=\"C2_0_c23b273ba0\"/>\r\n    </defs>\r\n    <g clip-path=\"url(#pe65df73cd0)\">\r\n     <use style=\"fill:#55a868;\" x=\"349.3195\" xlink:href=\"#C2_0_c23b273ba0\" y=\"213.924273\"/>\r\n    </g>\r\n    <g clip-path=\"url(#pe65df73cd0)\">\r\n     <use style=\"fill:#55a868;\" x=\"344.071304\" xlink:href=\"#C2_0_c23b273ba0\" y=\"213.793222\"/>\r\n    </g>\r\n    <g clip-path=\"url(#pe65df73cd0)\">\r\n     <use style=\"fill:#55a868;\" x=\"354.562282\" xlink:href=\"#C2_0_c23b273ba0\" y=\"213.66217\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pe65df73cd0\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"70.3195\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "sns.swarmplot(x=\"City\", y=\"Rent\", data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DSJ7eE5sk-4z",
    "outputId": "557f3477-67dd-48d8-f4d6-ba543d5d847c",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "One-hot encoding weights:  [[ 166.66666667  666.66666667 -833.33333333]]  and intercept:  [3333.33333333]\nDummy encoding weights:  [  500. -1000.]  and intercept:  3500.0\n"
    }
   ],
   "source": [
    "print('One-hot encoding weights: ' ,w1, ' and intercept: ', b1)\n",
    "print('Dummy encoding weights: ' ,w2, ' and intercept: ', b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uBNTUYMfk-41",
    "outputId": "c5f9da8f-7224-44af-f55f-fcfc9d9d2bbf"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m&lt;ipython-input-47-f17fe006c8dc&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m               \u001b[1;33m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mone_hot_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCity_SF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m               (w1[2] * one_hot_df.City_Seattle[i]) + b1) \n\u001b[1;32m----&gt; 7\u001b[1;33m              for i in range(0,one_hot_df.shape[0])]\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Create a list of values in the best fit line for dummy coding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m&lt;ipython-input-47-f17fe006c8dc&gt;\u001b[0m in \u001b[0;36m&lt;listcomp&gt;\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m               \u001b[1;33m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mone_hot_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCity_SF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m               (w1[2] * one_hot_df.City_Seattle[i]) + b1) \n\u001b[1;32m----&gt; 7\u001b[1;33m              for i in range(0,one_hot_df.shape[0])]\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Create a list of values in the best fit line for dummy coding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "\n",
    "# geometry of one-hot vs. dummy encoding\n",
    "\n",
    "# Create a list of values in the best fit line for one-hot encoding\n",
    "one_hot_y = [((w1[0] * one_hot_df.City_NY[i]) + \n",
    "              (w1[1] * one_hot_df.City_SF[i]) +\n",
    "              (w1[2] * one_hot_df.City_Seattle[i]) + b1) \n",
    "             for i in range(0,one_hot_df.shape[0])]\n",
    "\n",
    "# Create a list of values in the best fit line for dummy coding\n",
    "dummy_y = [((w2[0] * dummy_df.City_SF[i]) +\n",
    "            (w2[1] * dummy_df.City_Seattle[i]) + b2)\n",
    "           for i in range(0,dummy_df.shape[0])]\n",
    "\n",
    "print(one_hot_y)\n",
    "print(dummy_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iRdJWOvYk-43"
   },
   "source": [
    "\n",
    "Pros and Cons of Categorical Variable Encodings\n",
    "\n",
    "One-hot, dummy, and effect coding are very similar to one another. They each have pros and cons. One-hot encoding is redundant, which allows for multiple valid models for the same problem. The nonuniqueness is sometimes problematic for interpretation, but the advantage is that each feature clearly corresponds to a category. Moreover, missing data can be encoded as the all-zeros vector, and the output should be the overall mean of the target variable.\n",
    "\n",
    "Dummy coding and effect coding are not redundant. They give rise to unique and interpretable models. The downside of dummy coding is that it cannot easily handle missing data, since the all-zeros vector is already mapped to the reference category. It also encodes the effect of each category relative to the reference category, which may look strange.\n",
    "\n",
    "Effect coding avoids this problem by using a different code for the reference category, but the vector of all –1’s is a dense vector, which is expensive for both storage and computation. For this reason, popular ML software packages such as Pandas and scikit-learn have opted for dummy coding or one-hot encoding instead of effect coding.\n",
    "\n",
    "All three encoding techniques break down when the number of categories becomes very large. Different strategies are needed to handle extremely large categorical variables. \n",
    "\n",
    "## Dealing with Large Categorical Variables\n",
    "\n",
    "Automated data collection on the internet can generate large categorical variables. This is common in applications such as targeted advertising and fraud detection.\n",
    "\n",
    "In targeted advertising, the task is to match a user with a set of ads. Features include the user ID, the website domain for the ad, the search query, the current page, and all possible pairwise conjunctions of those features. (The query is a text string that can be chopped up and turned into the usual text features. However, queries are generally short and are often composed of phrases, so the best course of action in this case is usually to keep them intact, or pass them through a hash function to make storage and comparisons easier. We will discuss hashing in more detail later.) Each of these is a very large categorical variable. The challenge is to find a good feature representation that is memory efficient, yet produces accurate models that are fast to train.\n",
    "\n",
    "Existing solutions can be categorized (haha) thus:\n",
    "\n",
    "    Do nothing fancy with the encoding. Use a simple model that is cheap to train. Feed one-hot encoding into a linear model (logistic regression or linear support vector machine) on lots of machines.\n",
    "    Compress the features. There are two choices:\n",
    "        Feature hashing, popular with linear models\n",
    "        Bin counting, popular with linear models as well as trees\n",
    "\n",
    "Using the vanilla one-hot encoding is a valid option. For Microsoft’s search advertising engine, Graepel et al. (2010) report using such binary-valued features in a Bayesian probit regression model that can be trained online using simple updates. Meanwhile, other groups argue for the compression approach. Researchers from Yahoo! swear by feature hashing (Weinberger et al., 2009), though McMahan et al. (2013) experimented with feature hashing on Google’s advertising engine and did not find significant improvements. Yet other folks at Microsoft are taken with the idea of bin counting (Bilenko, 2015).\n",
    "\n",
    "As we shall see, all of these ideas have pros and cons. We will first describe the solutions themselves, then discuss their trade-offs.\n",
    "\n",
    "## Feature Hashing\n",
    "\n",
    "A hash function is a deterministic function that maps a potentially unbounded integer to a finite integer range [1, m]. Since the input domain is potentially larger than the output range, multiple numbers may get mapped to the same output. This is called a collision. A uniform hash function ensures that roughly the same number of numbers are mapped into each of the m bins.\n",
    "\n",
    "Visually, we can think of a hash function as a machine that intakes numbered balls (keys) and routes them to one of m bins. Balls with the same number will always get routed to the same bin (see Figure 5-1). This maintains the feature space while reducing the storage and processing time during machine learning training and evaluation cycles.\n",
    "\n",
    "Hash functions can be constructed for any object that can be represented numerically (which is true for any data that can be stored on a computer): numbers, strings, complex structures, etc.\n",
    "\n",
    "![texto alternativo](https://drive.google.com/uc?id=1cTY_mxkTAS33w9ck-Pn_8v67LspVGnTe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gz4j5b0yk-43"
   },
   "source": [
    "Feature hashing can be used for models that involve the inner product of feature vectors and coefficients, such as linear models and kernel methods. It has been demonstrated to be successful in the task of spam filtering (Weinberger et al., 2009). In the case of targeted advertising, McMahan et al. (2013) report not being able to get the prediction errors down to an acceptable level unless m is on the order of billions, which does not constitute enough saving in space.\n",
    "\n",
    "One downside to feature hashing is that the hashed features, being aggregates of original features, are no longer interpretable.\n",
    "\n",
    "In Example 5-5, we use the Yelp reviews dataset to demonstrate storage and interpretability trade-offs using scikit-learn’s FeatureHasher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cioioVKGk-44"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo de documento json\n",
    "# https://json.org/example.html"
   ]
  },
  {
   "source": [
    "\n",
    "# Load the first 10000 reviews\n",
    "'''f = open('yelp_academic_dataset_review.json', encoding=\"utf8\")\n",
    "js = []\n",
    "for i in range(10000):\n",
    "    js.append(json.loads(f.readline()))\n",
    "f.close()\n",
    "review_df = pd.DataFrame(js)\n",
    "review_df.shape'''\n",
    "\n",
    "\n",
    "\n",
    "# leer 'review.csv'\n",
    "\n",
    "review_df = pd.read_csv('./ficheros_FE_categoricas/review.csv')"
   ],
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XjfqmzhFk-45",
    "outputId": "376951c0-94d6-46ea-e259-bd339ac358c9"
   },
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Unnamed: 0               review_id                 user_id  \\\n0           0  xQY8N_XvtGbearJ5X4QryQ  OwjRMXRC0KyPrIlcjaXeFQ   \n1           1  UmFMZ8PyXZTY2QcwzsfQYA  nIJD_7ZXHq-FX8byPMOkMQ   \n2           2  LG2ZaYiOgpr2DK_90pYjNw  V34qejxNsCbcgD8C0HVk-Q   \n3           3  i6g_oA9Yf9Y31qt0wibXpw  ofKDkJKXSKZXu5xJNGiiBQ   \n4           4  6TdNDKywdbjoTkizeMce8A  UgMW8bLE0QMJDCkQ1Ax5Mg   \n\n              business_id  stars  useful  funny  cool  \\\n0  -MhfebM0QIsKt87iDN-FNw    2.0       5      0     0   \n1  lbrU8StCq3yDfr-QMnGrmQ    1.0       1      1     0   \n2  HQl28KMwrEKHqhFrrDqVNQ    5.0       1      0     0   \n3  5JxlZaqCnk1MnbgRirs40Q    1.0       0      0     0   \n4  IS4cv902ykd8wj1TR0N3-A    4.0       0      0     0   \n\n                                                text                 date  \n0  As someone who has worked with many museums, I...  2015-04-15 05:21:16  \n1  I am actually horrified this place is still in...  2013-12-07 03:16:52  \n2  I love Deagan&#39;s. I do. I really do. The atmosp...  2015-12-05 03:18:11  \n3  Dismal, lukewarm, defrosted-tasting &quot;TexMex&quot; g...  2011-05-27 05:30:52  \n4  Oh happy day, finally have a Canes near my cas...  2017-01-14 21:56:57  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>review_id</th>\n      <th>user_id</th>\n      <th>business_id</th>\n      <th>stars</th>\n      <th>useful</th>\n      <th>funny</th>\n      <th>cool</th>\n      <th>text</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0</td>\n      <td>xQY8N_XvtGbearJ5X4QryQ</td>\n      <td>OwjRMXRC0KyPrIlcjaXeFQ</td>\n      <td>-MhfebM0QIsKt87iDN-FNw</td>\n      <td>2.0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>As someone who has worked with many museums, I...</td>\n      <td>2015-04-15 05:21:16</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1</td>\n      <td>UmFMZ8PyXZTY2QcwzsfQYA</td>\n      <td>nIJD_7ZXHq-FX8byPMOkMQ</td>\n      <td>lbrU8StCq3yDfr-QMnGrmQ</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>I am actually horrified this place is still in...</td>\n      <td>2013-12-07 03:16:52</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2</td>\n      <td>LG2ZaYiOgpr2DK_90pYjNw</td>\n      <td>V34qejxNsCbcgD8C0HVk-Q</td>\n      <td>HQl28KMwrEKHqhFrrDqVNQ</td>\n      <td>5.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>I love Deagan's. I do. I really do. The atmosp...</td>\n      <td>2015-12-05 03:18:11</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3</td>\n      <td>i6g_oA9Yf9Y31qt0wibXpw</td>\n      <td>ofKDkJKXSKZXu5xJNGiiBQ</td>\n      <td>5JxlZaqCnk1MnbgRirs40Q</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Dismal, lukewarm, defrosted-tasting \"TexMex\" g...</td>\n      <td>2011-05-27 05:30:52</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>4</td>\n      <td>6TdNDKywdbjoTkizeMce8A</td>\n      <td>UgMW8bLE0QMJDCkQ1Ax5Mg</td>\n      <td>IS4cv902ykd8wj1TR0N3-A</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Oh happy day, finally have a Canes near my cas...</td>\n      <td>2017-01-14 21:56:57</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.drop('Unnamed: 0', axis=1,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                review_id                 user_id             business_id  \\\n0  xQY8N_XvtGbearJ5X4QryQ  OwjRMXRC0KyPrIlcjaXeFQ  -MhfebM0QIsKt87iDN-FNw   \n1  UmFMZ8PyXZTY2QcwzsfQYA  nIJD_7ZXHq-FX8byPMOkMQ  lbrU8StCq3yDfr-QMnGrmQ   \n2  LG2ZaYiOgpr2DK_90pYjNw  V34qejxNsCbcgD8C0HVk-Q  HQl28KMwrEKHqhFrrDqVNQ   \n3  i6g_oA9Yf9Y31qt0wibXpw  ofKDkJKXSKZXu5xJNGiiBQ  5JxlZaqCnk1MnbgRirs40Q   \n4  6TdNDKywdbjoTkizeMce8A  UgMW8bLE0QMJDCkQ1Ax5Mg  IS4cv902ykd8wj1TR0N3-A   \n\n   stars  useful  funny  cool  \\\n0    2.0       5      0     0   \n1    1.0       1      1     0   \n2    5.0       1      0     0   \n3    1.0       0      0     0   \n4    4.0       0      0     0   \n\n                                                text                 date  \n0  As someone who has worked with many museums, I...  2015-04-15 05:21:16  \n1  I am actually horrified this place is still in...  2013-12-07 03:16:52  \n2  I love Deagan&#39;s. I do. I really do. The atmosp...  2015-12-05 03:18:11  \n3  Dismal, lukewarm, defrosted-tasting &quot;TexMex&quot; g...  2011-05-27 05:30:52  \n4  Oh happy day, finally have a Canes near my cas...  2017-01-14 21:56:57  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_id</th>\n      <th>user_id</th>\n      <th>business_id</th>\n      <th>stars</th>\n      <th>useful</th>\n      <th>funny</th>\n      <th>cool</th>\n      <th>text</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>xQY8N_XvtGbearJ5X4QryQ</td>\n      <td>OwjRMXRC0KyPrIlcjaXeFQ</td>\n      <td>-MhfebM0QIsKt87iDN-FNw</td>\n      <td>2.0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>As someone who has worked with many museums, I...</td>\n      <td>2015-04-15 05:21:16</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>UmFMZ8PyXZTY2QcwzsfQYA</td>\n      <td>nIJD_7ZXHq-FX8byPMOkMQ</td>\n      <td>lbrU8StCq3yDfr-QMnGrmQ</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>I am actually horrified this place is still in...</td>\n      <td>2013-12-07 03:16:52</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>LG2ZaYiOgpr2DK_90pYjNw</td>\n      <td>V34qejxNsCbcgD8C0HVk-Q</td>\n      <td>HQl28KMwrEKHqhFrrDqVNQ</td>\n      <td>5.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>I love Deagan's. I do. I really do. The atmosp...</td>\n      <td>2015-12-05 03:18:11</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>i6g_oA9Yf9Y31qt0wibXpw</td>\n      <td>ofKDkJKXSKZXu5xJNGiiBQ</td>\n      <td>5JxlZaqCnk1MnbgRirs40Q</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Dismal, lukewarm, defrosted-tasting \"TexMex\" g...</td>\n      <td>2011-05-27 05:30:52</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>6TdNDKywdbjoTkizeMce8A</td>\n      <td>UgMW8bLE0QMJDCkQ1Ax5Mg</td>\n      <td>IS4cv902ykd8wj1TR0N3-A</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Oh happy day, finally have a Canes near my cas...</td>\n      <td>2017-01-14 21:56:57</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Yitj15Nk-48",
    "outputId": "80ccb0dc-2c4e-4fff-9ab9-ee32a6c6afec"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4398"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "# we will define m as equal to the unique number of business_id\n",
    "m = review_df['business_id'].unique().size\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYQ4GApHk-4-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n1zgBLs4k-4_"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = FeatureHasher(n_features= m , input_type= 'string')\n",
    "f = h.transform(review_df['business_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B26iwQt5k-5B",
    "outputId": "e0c2a8e0-8ca4-4001-e757-4eb41df149f5",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Our pandas Series, in bytes:  790152\nOur hashed numpy array, in bytes:  56\n"
    }
   ],
   "source": [
    "\n",
    "# We can see how this will make a difference in the future by looking at the size of each\n",
    "from sys import getsizeof\n",
    "\n",
    "print('Our pandas Series, in bytes: ', getsizeof(review_df['business_id']))\n",
    "print('Our hashed numpy array, in bytes: ', getsizeof(f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5nPziZdlk-5D",
    "outputId": "be4448f2-521c-4cad-8e7e-486e191401ae"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[&#39;-MhfebM0QIsKt87iDN-FNw&#39;,\n &#39;lbrU8StCq3yDfr-QMnGrmQ&#39;,\n &#39;HQl28KMwrEKHqhFrrDqVNQ&#39;,\n &#39;5JxlZaqCnk1MnbgRirs40Q&#39;,\n &#39;IS4cv902ykd8wj1TR0N3-A&#39;]"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "review_df['business_id'].unique().tolist()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kx7IXr4bk-5F",
    "outputId": "0c9626ca-66c5-4aeb-9fd3-7eb4890bc8d8"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&lt;10000x4398 sparse matrix of type &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39;\n\twith 187353 stored elements in Compressed Sparse Row format&gt;"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "f #Es la transformación a una matriz dispersa, con muchos ceros... para guardar de forma más optima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kbW1gwz3k-5G"
   },
   "source": [
    "## Bin Counting\n",
    "\n",
    "Bin counting is one of the perennial rediscoveries in machine learning. It has been reinvented and used in a variety of applications, from ad click-through rate prediction to hardware branch prediction (Yeh and Patt, 1991; Lee et al., 1998; Chen et al., 2009; Li et al., 2010). Yet because it is a feature engineering technique and not a modeling or optimization method, there is no research paper on the topic. The most detailed description of the technique can be found in Misha Bilenko’s (2015) blog post “Big Learning Made Easy—with Counts!” and the associated slides.\n",
    "\n",
    "The idea of bin counting is deviously simple: rather than using the value of the categorical variable as the feature, instead use the conditional probability of the target under that value. In other words, instead of encoding the identity of the categorical value, we compute the association statistics between that value and the target that we wish to predict. For those familiar with naive Bayes classifiers, this statistic should ring a bell, because it is the conditional probability of the class under the assumption that all features are independent. It is best illustrated with an example (see Table 5-6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YMzAMxEck-5H"
   },
   "source": [
    "![texto alternativo](https://drive.google.com/uc?id=1Zz3RhCWdF-Zf_q0ro_Lrjqj_LZK8auJ_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SUARA_V8k-5H"
   },
   "source": [
    "Bin counting assumes that historical data is available for computing the statistics. Table 5-6 contains aggregated historical counts for each possible value of the categorical variables. Based on the number of times the user “Alice” has clicked on any ad and the number of times she has not clicked, we can calculate the probability of her clicking on any ad. Similarly, we can compute the probability of a click for any query–ad domain combination. At training time, every time we see “Alice,” we can use her probability of click as the input feature to the model. The same goes for QueryHash–AdDomain pairs like “0x437a45e1, qux.net.”\n",
    "\n",
    "Suppose there were 10,000 users. One-hot encoding would generate a sparse vector of length 10,000, with a single 1 in the column that corresponds to the value of the current data point. Bin counting would encode all 10,000 binary columns as a single feature with a real value between 0 and 1.\n",
    "\n",
    "We can include other features in addition to the historical click-through probability: the raw counts themselves (number of clicks and nonclicks), the log-odds ratio, or any other derivatives of probability. Our example here is for predicting ad click-through rates, but the technique readily applies to general binary classification. It can also be readily extended to multiclass classification using the usual techniques to extend binary classifiers to multiclass; i.e., via one-against-many odds ratios or other multiclass label encodings.\n",
    "\n",
    "In short, bin counting converts a categorical variable into statistics about the value. It turns a large, sparse, binary representation of the categorical variable, such as that produced by one-hot encoding, into a very small, dense, real-valued numeric representation (Figure 5-2).\n",
    "\n",
    "n terms of implementation, bin counting requires storing a map between each category and its associated counts. (The rest of the statistics can be derived on the fly from the raw counts.) Hence it requires O(k) space, where k is the number of unique values of the categorical variable.\n",
    "\n",
    "To illustrate bin counting in practice, we’ll use data from a Kaggle competition hosted by Avazu. Here are some relevant statistics about the dataset:\n",
    "\n",
    "- There are 24 variables, including click, a binary click/no click counter, and device_id, which tracks which device an ad was displayed on.\n",
    "- The full dataset contains 40,428,967 observations, with 2,686,408 unique devices.\n",
    "\n",
    "The aim of the Avazu competition was to predict click-through rate using ad data, but we will use the dataset to demonstrate how bin counting can greatly reduce the feature space for large amounts of streaming data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KUy0n_Zbk-5H"
   },
   "source": [
    "## Bin counting Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fq8PREgCk-5I"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wADbnvOCk-5J"
   },
   "source": [
    "- [Click-through ad data from Kaggle competition](https://www.kaggle.com/c/avazu-ctr-prediction/data)\n",
    "- train_subset is first 10K rows of 6+GB set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ARVIySYk-5K"
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('./ficheros_FE_categoricas/train_10k.csv', nrows = 10000)\n",
    "\n",
    "\n",
    "# leer 'train_10k.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Unnamed: 0                    id  click      hour    C1  banner_pos  \\\n0           0   1000009418151094273      0  14102100  1005           0   \n1           1  10000169349117863715      0  14102100  1005           0   \n2           2  10000371904215119486      0  14102100  1005           0   \n3           3  10000640724480838376      0  14102100  1005           0   \n4           4  10000679056417042096      0  14102100  1005           1   \n\n    site_id site_domain site_category    app_id  ... device_type  \\\n0  1fbe01fe    f3845767      28905ebd  ecad2386  ...           1   \n1  1fbe01fe    f3845767      28905ebd  ecad2386  ...           1   \n2  1fbe01fe    f3845767      28905ebd  ecad2386  ...           1   \n3  1fbe01fe    f3845767      28905ebd  ecad2386  ...           1   \n4  fe8cc448    9166c161      0569f928  ecad2386  ...           1   \n\n  device_conn_type    C14  C15 C16   C17  C18  C19     C20  C21  \n0                2  15706  320  50  1722    0   35      -1   79  \n1                0  15704  320  50  1722    0   35  100084   79  \n2                0  15704  320  50  1722    0   35  100084   79  \n3                0  15706  320  50  1722    0   35  100084   79  \n4                0  18993  320  50  2161    0   35      -1  157  \n\n[5 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>click</th>\n      <th>hour</th>\n      <th>C1</th>\n      <th>banner_pos</th>\n      <th>site_id</th>\n      <th>site_domain</th>\n      <th>site_category</th>\n      <th>app_id</th>\n      <th>...</th>\n      <th>device_type</th>\n      <th>device_conn_type</th>\n      <th>C14</th>\n      <th>C15</th>\n      <th>C16</th>\n      <th>C17</th>\n      <th>C18</th>\n      <th>C19</th>\n      <th>C20</th>\n      <th>C21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0</td>\n      <td>1000009418151094273</td>\n      <td>0</td>\n      <td>14102100</td>\n      <td>1005</td>\n      <td>0</td>\n      <td>1fbe01fe</td>\n      <td>f3845767</td>\n      <td>28905ebd</td>\n      <td>ecad2386</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2</td>\n      <td>15706</td>\n      <td>320</td>\n      <td>50</td>\n      <td>1722</td>\n      <td>0</td>\n      <td>35</td>\n      <td>-1</td>\n      <td>79</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1</td>\n      <td>10000169349117863715</td>\n      <td>0</td>\n      <td>14102100</td>\n      <td>1005</td>\n      <td>0</td>\n      <td>1fbe01fe</td>\n      <td>f3845767</td>\n      <td>28905ebd</td>\n      <td>ecad2386</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>15704</td>\n      <td>320</td>\n      <td>50</td>\n      <td>1722</td>\n      <td>0</td>\n      <td>35</td>\n      <td>100084</td>\n      <td>79</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2</td>\n      <td>10000371904215119486</td>\n      <td>0</td>\n      <td>14102100</td>\n      <td>1005</td>\n      <td>0</td>\n      <td>1fbe01fe</td>\n      <td>f3845767</td>\n      <td>28905ebd</td>\n      <td>ecad2386</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>15704</td>\n      <td>320</td>\n      <td>50</td>\n      <td>1722</td>\n      <td>0</td>\n      <td>35</td>\n      <td>100084</td>\n      <td>79</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3</td>\n      <td>10000640724480838376</td>\n      <td>0</td>\n      <td>14102100</td>\n      <td>1005</td>\n      <td>0</td>\n      <td>1fbe01fe</td>\n      <td>f3845767</td>\n      <td>28905ebd</td>\n      <td>ecad2386</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>15706</td>\n      <td>320</td>\n      <td>50</td>\n      <td>1722</td>\n      <td>0</td>\n      <td>35</td>\n      <td>100084</td>\n      <td>79</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>4</td>\n      <td>10000679056417042096</td>\n      <td>0</td>\n      <td>14102100</td>\n      <td>1005</td>\n      <td>1</td>\n      <td>fe8cc448</td>\n      <td>9166c161</td>\n      <td>0569f928</td>\n      <td>ecad2386</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>18993</td>\n      <td>320</td>\n      <td>50</td>\n      <td>2161</td>\n      <td>0</td>\n      <td>35</td>\n      <td>-1</td>\n      <td>157</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7VXjcqvsk-5N",
    "outputId": "2cd4ba8c-c40e-4132-ddd4-00891db85ab1"
   },
   "outputs": [],
   "source": [
    "# how many features should we have after?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QM3DVKuEk-5P"
   },
   "source": [
    "Features are $\\theta$ = [$N^+$, $N^-$, $log(N^+)-log(N^-)$, isRest]\n",
    "\n",
    "$N^+$ = $p(+)$ = $n^+/(n^+ + n^-)$\n",
    "\n",
    "$N^-$ = $p(-)$ = $n^-/(n^+ + n^-)$\n",
    "\n",
    "$log(N^+)-log(N^-)$ = $\\frac{p(+)}{p(-)}$\n",
    "\n",
    "isRest = back-off bin (not shown here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8tJu-qhTk-5P"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef click_counting(x, bin_column):\\n    clicks = pd.Series(x[x['click'] > 0][bin_column].value_counts(), name='clicks')\\n    no_clicks = pd.Series(x[x['click'] < 1][bin_column].value_counts(), name='no_clicks')\\n    \\n    counts = pd.DataFrame([clicks,no_clicks]).T.fillna('0')\\n    counts['total'] = counts['clicks'].astype('int64') + counts['no_clicks'].astype('int64')\\n    \\n    return counts\\n\\ndef bin_counting(counts):\\n    counts['N+'] = counts['clicks'].astype('int64').divide(counts['total'].astype('int64'))\\n    counts['N-'] = counts['no_clicks'].astype('int64').divide(counts['total'].astype('int64'))\\n    counts['log_N+'] = counts['N+'].divide(counts['N-'])\\n\\n#    If we wanted to only return bin-counting properties, we would filter here\\n    bin_counts = counts.filter(items= ['N+', 'N-', 'log_N+'])\\n    return counts, bin_counts\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def click_counting(x, bin_column):\n",
    "    clicks = pd.Series(x[x['click'] > 0][bin_column].value_counts(), name='clicks')\n",
    "    no_clicks = pd.Series(x[x['click'] < 1][bin_column].value_counts(), name='no_clicks')\n",
    "    \n",
    "    counts = pd.DataFrame([clicks,no_clicks]).T.fillna('0')\n",
    "    counts['total'] = counts['clicks'].astype('int64') + counts['no_clicks'].astype('int64')\n",
    "    \n",
    "    return counts\n",
    "\n",
    "def bin_counting(counts):\n",
    "    counts['N+'] = counts['clicks'].astype('int64').divide(counts['total'].astype('int64'))\n",
    "    counts['N-'] = counts['no_clicks'].astype('int64').divide(counts['total'].astype('int64'))\n",
    "    counts['log_N+'] = counts['N+'].divide(counts['N-'])\n",
    "\n",
    "#    If we wanted to only return bin-counting properties, we would filter here\n",
    "    bin_counts = counts.filter(items= ['N+', 'N-', 'log_N+'])\n",
    "    return counts, bin_counts\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aqSoKybyk-5R"
   },
   "outputs": [],
   "source": [
    "# bin counts example: device_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tVoCydSDk-5T",
    "outputId": "0c812c4b-4a52-40cc-f4c7-d6e7df324b23"
   },
   "outputs": [],
   "source": [
    "# check to make sure we have all the devices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sShErmckk-5W",
    "outputId": "12671f8b-4c4b-452d-b886-719c0f1b1bb9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r0iOjVwlk-5Z",
    "outputId": "a3b9557c-688f-42bf-b5c9-4122382b13ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n# We can see how this can change model evaluation time by comparing raw vs. bin-counting size\\nfrom sys import getsizeof\\n\\nprint('Our pandas Series, in bytes: ', getsizeof(df.filter(items= ['device_id', 'click'])))\\nprint('Our bin-counting feature, in bytes: ', getsizeof(device_bin_counts))\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "# We can see how this can change model evaluation time by comparing raw vs. bin-counting size\n",
    "from sys import getsizeof\n",
    "\n",
    "print('Our pandas Series, in bytes: ', getsizeof(df.filter(items= ['device_id', 'click'])))\n",
    "print('Our bin-counting feature, in bytes: ', getsizeof(device_bin_counts))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1-CategoricalData.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}