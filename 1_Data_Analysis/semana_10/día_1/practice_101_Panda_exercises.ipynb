{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.4 64-bit ('base': conda)",
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "3b7ad80724233561a6164c9de25185dd16a182b727dd421b2c1c74f17069d1e3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## 101 Pandas Exercises for Data Analysis \n",
    "https://www.machinelearningplus.com/python/101-pandas-exercises-python/\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 1. How to import pandas and check the version?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'0.25.1'"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'system': {'commit': None, 'python': '3.7.4.final.0', 'python-bits': 64, 'OS': 'Windows', 'OS-release': '10', 'machine': 'AMD64', 'processor': 'Intel64 Family 6 Model 142 Stepping 10, GenuineIntel', 'byteorder': 'little', 'LC_ALL': 'None', 'LANG': 'None', 'LOCALE': 'None.None'}, 'dependencies': {'pandas': '0.25.1', 'numpy': '1.18.1', 'pytz': '2019.3', 'dateutil': '2.8.0', 'pip': '19.2.3', 'setuptools': '41.4.0', 'Cython': '0.29.13', 'pytest': '5.2.1', 'hypothesis': None, 'sphinx': '2.2.0', 'blosc': None, 'feather': None, 'xlsxwriter': '1.2.1', 'lxml.etree': '4.4.1', 'html5lib': '1.0.1', 'pymysql': None, 'psycopg2': None, 'jinja2': '2.10.3', 'IPython': '7.8.0', 'pandas_datareader': None, 'bs4': '4.8.0', 'bottleneck': '1.2.1', 'fastparquet': None, 'gcsfs': None, 'matplotlib': '3.1.1', 'numexpr': '2.7.0', 'odfpy': None, 'openpyxl': '3.0.0', 'pandas_gbq': None, 'pyarrow': None, 'pytables': None, 's3fs': None, 'scipy': '1.3.1', 'sqlalchemy': '1.3.9', 'tables': '3.5.2', 'xarray': None, 'xlrd': '1.2.0', 'xlwt': '1.3.0'}}\n"
    }
   ],
   "source": [
    "#Book solution\n",
    "pd.show_versions(as_json=True)"
   ]
  },
  {
   "source": [
    "#### 2. How to create a series from a list, numpy array and dict?\n",
    "Create a pandas series from each of the items below: a list, numpy and a dictionary\n",
    "\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "\n",
    "myarr = np.arange(26)\n",
    "\n",
    "mydict = dict(zip(mylist, myarr))"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(26)\n",
    "mydict = dict(zip(mylist, myarr))"
   ]
  },
  {
   "source": [
    "mylist = pd.Series(mylist)\n",
    "\n",
    "myarr = pd.Series(myarr)\n",
    "\n",
    "mydict = pd.Series(mydict)\n"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0    a\n1    b\n2    c\n3    e\n4    d\ndtype: object\n"
    }
   ],
   "source": [
    "print(mylist[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0    0\n1    1\n2    2\n3    3\n4    4\ndtype: int32\n"
    }
   ],
   "source": [
    "print(myarr[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "a    0\nb    1\nc    2\ne    3\nd    4\ndtype: int64\n"
    }
   ],
   "source": [
    "print(mydict[:5])"
   ]
  },
  {
   "source": [
    "#### 3. How to convert the index of a series into a column of a dataframe?\n",
    "\n",
    "Difficulty Level: L1\n",
    "\n",
    "Convert the series ser into a dataframe with its index as another column on the dataframe."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "a    0\nb    1\nc    2\ne    3\nd    4\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(26)\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "ser = pd.Series(mydict)\n",
    "ser[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  Col1  Col2\n0    a     0\n1    b     1\n2    c     2\n3    e     3\n4    d     4",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Col1</th>\n      <th>Col2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>a</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>b</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>c</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>e</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>d</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "ser\n",
    "df = pd.DataFrame({\"Col1\": ser.index, \"Col2\":ser.values}, index=ser)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "  index  0\n0     a  0\n1     b  1\n2     c  2\n3     e  3\n4     d  4\n"
    }
   ],
   "source": [
    "# Solution \n",
    "df = ser.to_frame().reset_index()\n",
    "print(df.head())"
   ]
  },
  {
   "source": [
    "#### 4. How to combine many series to form a dataframe?\n",
    "Difficulty Level: L1\n",
    "\n",
    "Combine ser1 and ser2 to form a dataframe."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input\n",
    "import numpy as np\n",
    "ser1 = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "ser2 = pd.Series(np.arange(26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Col_1': ser1,\n",
    "                   'Col_2': ser2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  Col_1  Col_2\n0     a      0\n1     b      1\n2     c      2\n3     e      3\n4     d      4",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Col_1</th>\n      <th>Col_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>a</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>b</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>c</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>e</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>d</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "pandas.core.frame.DataFrame"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# Book Solution 1\n",
    "df = pd.concat([ser1, ser2], axis=1) #axis = 1 = Columns\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "  col1  col2\n0    a     0\n1    b     1\n2    c     2\n3    e     3\n4    d     4\n"
    }
   ],
   "source": [
    "# Book Solution 2\n",
    "df = pd.DataFrame({'col1': ser1, 'col2': ser2})\n",
    "print(df.head())"
   ]
  },
  {
   "source": [
    "#### 5. How to assign name to the series’ index?\n",
    "Difficulty Level: L1\n",
    "\n",
    "Give a name to the series ser calling it ‘alphabets’."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input\n",
    "ser = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    a\n1    b\n2    c\n3    e\n4    d\nName: alphabets, dtype: object"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "ser.rename('alphabets')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    a\n1    b\n2    c\n3    e\n4    d\nName: alphabets, dtype: object"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# Book Solution\n",
    "ser.name = 'alphabets'\n",
    "ser.head()"
   ]
  },
  {
   "source": [
    "#### 6. How to get the items of series A not present in series B?\n",
    "Difficulty Level: L2\n",
    "\n",
    "From ser1 remove items present in ser2."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = ser1[~(ser1.isin(ser2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    1\n1    2\n2    3\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "ser1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    1\n1    2\n2    3\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# Book Solution\n",
    "ser1[~ser1.isin(ser2)]"
   ]
  },
  {
   "source": [
    "#### 7. How to get the items not common to both series A and series B?\n",
    "Difficulty Level: L2\n",
    "\n",
    "Get all items of ser1 and ser2 not common to both."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    1\n1    2\n2    3\n2    6\n3    7\n4    8\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "not_common = pd.concat([ser1[~ser1.isin(ser2)],ser2[~ser2.isin(ser1)]])\n",
    "not_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    1\n1    2\n2    3\n5    6\n6    7\n7    8\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "#Book solution\n",
    "\n",
    "ser_u = pd.Series(np.union1d(ser1, ser2))  # union\n",
    "ser_i = pd.Series(np.intersect1d(ser1, ser2))  # intersect\n",
    "ser_u[~ser_u.isin(ser_i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "ser_u[~ser_u.isin(ser_i)].all() == not_common.all()"
   ]
  },
  {
   "source": [
    "#### 8. How to get the minimum, 25th percentile, median, 75th, and max of a numeric series?\n",
    "Difficuty Level: L2\n",
    "\n",
    "Compute the minimum, 25th percentile, median, 75th, and maximum of ser."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input \n",
    "np.random.seed(10)\n",
    "ser = pd.Series(np.random.normal(10, 5, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    16.657933\n1    13.576395\n2     2.272999\n3     9.958081\n4    13.106680\ndtype: float64"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "ser[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "count    25.000000\nmean     10.485604\nstd       5.398767\nmin       0.111359\n25%       6.399572\n50%      11.143151\n75%      13.576395\nmax      21.924837\ndtype: float64"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "ser.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ 0.1113586 ,  6.3995722 , 11.14315065, 13.57639487, 21.92483665])"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "#Book solution\n",
    "np.percentile(ser, q=[0, 25, 50, 75, 100])"
   ]
  },
  {
   "source": [
    "#### 9. How to get frequency counts of unique items of a series?\n",
    "Difficulty Level: L1\n",
    "\n",
    "Calculte the frequency counts of each unique value ser."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "a    7\nh    5\ne    5\nb    3\nc    3\nd    3\ng    3\nf    1\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "ser.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "a    7\nh    5\ne    5\nb    3\nc    3\nd    3\ng    3\nf    1\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# Book Solution\n",
    "ser.value_counts()"
   ]
  },
  {
   "source": [
    "#### 10. How to keep only top 2 most frequent values as it is and replace everything else as ‘Other’?\n",
    "Difficulty Level: L2\n",
    "\n",
    "From ser, keep the top 2 most frequent items as it is and replace everything else as ‘Other’."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0     1\n1     3\n2     1\n3     3\n4     3\n5     1\n6     4\n7     2\n8     1\n9     4\n10    2\n11    3\ndtype: int32\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3    4\n1    4\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "np.random.RandomState(100)\n",
    "ser = pd.Series(np.random.randint(1, 5, [12]))\n",
    "print(ser)\n",
    "ser.value_counts()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Int64Index([3, 1], dtype='int64')"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "ser.value_counts()[:2].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser[~(ser.isin(ser.value_counts()[:2].index))] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0         1\n1         3\n2         1\n3         3\n4         3\n5         1\n6     Other\n7     Other\n8         1\n9     Other\n10    Other\n11        3\ndtype: object"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Top 2 Freq: 3        4\n1        4\nOther    4\ndtype: int64\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0         1\n1         3\n2         1\n3         3\n4         3\n5         1\n6     Other\n7     Other\n8         1\n9     Other\n10    Other\n11        3\ndtype: object"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "# Book Solution\n",
    "print(\"Top 2 Freq:\", ser.value_counts())\n",
    "ser[~ser.isin(ser.value_counts().index[:2])] = 'Other'\n",
    "ser"
   ]
  },
  {
   "source": [
    "#### 11. How to bin a numeric series to 10 groups of equal size?\n",
    "Difficulty Level: L2\n",
    "\n",
    "Bin the series ser into 10 equal deciles and replace the values with the bin name."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0     0.093460\n1     0.821106\n2     0.151152\n3     0.384114\n4     0.944261\n5     0.987625\n6     0.456305\n7     0.826123\n8     0.251374\n9     0.597372\n10    0.902832\n11    0.534558\n12    0.590201\n13    0.039282\n14    0.357182\n15    0.079613\n16    0.305460\n17    0.330719\n18    0.773830\n19    0.039959\ndtype: float64"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "ser = pd.Series(np.random.random(20))\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0     2nd\n1     8th\n2     3rd\n3     5th\n4    10th\ndtype: category\nCategories (10, object): [1st < 2nd < 3rd < 4th ... 7th < 8th < 9th < 10th]"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "# Book Solution\n",
    "pd.qcut(ser, q=[0, .10, .20, .3, .4, .5, .6, .7, .8, .9, 1], \n",
    "        labels=['1st', '2nd', '3rd', '4th', '5th', '6th', '7th', '8th', '9th', '10th']).head()"
   ]
  },
  {
   "source": [
    "#### 12. How to convert a numpy array to a dataframe of given shape? (L1)\n",
    "Difficulty Level: L1\n",
    "\n",
    "Reshape the series ser into a dataframe with 7 rows and 5 columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0     2\n1     3\n2     6\n3     1\n4     2\n5     1\n6     2\n7     1\n8     3\n9     2\n10    2\n11    1\n12    1\n13    6\n14    1\n15    5\n16    7\n17    7\n18    1\n19    3\n20    4\n21    4\n22    3\n23    7\n24    1\n25    6\n26    2\n27    4\n28    7\n29    6\n30    6\n31    2\n32    9\n33    1\n34    6\ndtype: int32"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "#input\n",
    "ser = pd.Series(np.random.randint(1, 10, 35))\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   0  1  2  3  4\n0  2  3  6  1  2\n1  1  2  1  3  2\n2  2  1  1  6  1\n3  5  7  7  1  3\n4  4  4  3  7  1\n5  6  2  4  7  6\n6  6  2  9  1  6",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>5</td>\n      <td>7</td>\n      <td>7</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>6</td>\n      <td>2</td>\n      <td>4</td>\n      <td>7</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>6</td>\n      <td>2</td>\n      <td>9</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "pd.DataFrame(ser.values.reshape(7,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   0  1  2  3  4\n0  2  3  6  1  2\n1  1  2  1  3  2\n2  2  1  1  6  1\n3  5  7  7  1  3\n4  4  4  3  7  1\n5  6  2  4  7  6\n6  6  2  9  1  6",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>5</td>\n      <td>7</td>\n      <td>7</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>6</td>\n      <td>2</td>\n      <td>4</td>\n      <td>7</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>6</td>\n      <td>2</td>\n      <td>9</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "# Book Solution\n",
    "df = pd.DataFrame(ser.values.reshape(7,5))\n",
    "df"
   ]
  },
  {
   "source": [
    "#### 13. How to find the positions of numbers that are multiples of 3 from a series?\n",
    "Difficulty Level: L2\n",
    "\n",
    "Find the positions of numbers that are multiples of 3 from ser.\n",
    "\n",
    "Input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    9\n1    6\n2    8\n3    9\n4    6\n5    9\n6    2\ndtype: int32"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "ser = pd.Series(np.random.randint(1, 10, 7))\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0    9\n1    6\n3    9\n4    6\n5    9\ndtype: int32\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Int64Index([0, 1, 3, 4, 5], dtype='int64')"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "mask = ser.values%3 == 0\n",
    "print(ser[mask])\n",
    "ser[mask].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0    9\n1    6\n2    8\n3    9\n4    6\n5    9\n6    2\ndtype: int32\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0],\n       [1],\n       [3],\n       [4],\n       [5]], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "# Book Solution\n",
    "print(ser)\n",
    "np.argwhere(ser % 3==0)"
   ]
  },
  {
   "source": [
    "#### 14. How to extract items at given positions from a series\n",
    "Difficulty Level: L1\n",
    "\n",
    "From ser, extract the items at positions in list pos.\n",
    "\n",
    "Input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "pos = [0, 4, 8, 14, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0     a\n4     e\n8     i\n14    o\n20    u\ndtype: object"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "ser[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0     a\n4     e\n8     i\n14    o\n20    u\ndtype: object"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "# Book Solution\n",
    "ser.take(pos)"
   ]
  },
  {
   "source": [
    "#### 15. How to stack two series vertically and horizontally ?\n",
    "Difficulty Level: L1\n",
    "\n",
    "Stack ser1 and ser2 vertically and horizontally (to form a dataframe).\n",
    "\n",
    "Input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series(range(5))\n",
    "ser2 = pd.Series(list('abcde'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    0\n1    1\n2    2\n3    3\n4    4\n0    a\n1    b\n2    c\n3    d\n4    e\ndtype: object"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "#Vertically\n",
    "pd.concat([ser1,ser2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   0  1\n0  0  a\n1  1  b\n2  2  c\n3  3  d\n4  4  e",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2</td>\n      <td>c</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3</td>\n      <td>d</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>4</td>\n      <td>e</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "#Horizontally\n",
    "pd.concat([ser1,ser2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "   0  1\n0  0  a\n1  1  b\n2  2  c\n3  3  d\n4  4  e\n"
    }
   ],
   "source": [
    "# Book solution\n",
    "# Vertical\n",
    "ser1.append(ser2)\n",
    "\n",
    "# Horizontal\n",
    "df = pd.concat([ser1, ser2], axis=1)\n",
    "print(df)"
   ]
  },
  {
   "source": [
    "#### 16. How to get the positions of items of series A in another series B?\n",
    "Difficulty Level: L2\n",
    "\n",
    "Get the positions of items of ser2 in ser1 as a list.\n",
    "\n",
    "Input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series([10, 9, 6, 5, 3, 1, 12, 8, 13])\n",
    "ser2 = pd.Series([1, 3, 10, 13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Int64Index([0, 4, 5, 8], dtype='int64')"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "ser1[ser1.isin(ser2)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[5, 4, 0, 8]"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "# Book Solution 1\n",
    "[np.where(i == ser1)[0].tolist()[0] for i in ser2]\n",
    "\n",
    "# Book Solution 2\n",
    "[pd.Index(ser1).get_loc(i) for i in ser2]"
   ]
  },
  {
   "source": [
    "#### 17. How to compute the mean squared error on a truth and predicted series?\n",
    "Difficulty Level: L2\n",
    "\n",
    "Compute the mean squared error of truth and pred series.\n",
    "\n",
    "Input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = pd.Series(range(10))\n",
    "pred = pd.Series(range(10)) + np.random.random(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.1867779426084901"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "# Book Solution\n",
    "np.mean((truth-pred)**2)"
   ]
  },
  {
   "source": [
    "#### 18. How to convert the first character of each element in a series to uppercase?\n",
    "Difficulty Level: L2\n",
    "\n",
    "Change the first character of each word to upper case in each word of ser."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0     how\n1      to\n2    kick\n3    ass?\ndtype: object"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0     How\n1      To\n2    Kick\n3    Ass?\ndtype: object"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "ser = pd.Series([x[:1].upper()+x[1:] for x in ser])\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0     How\n1      To\n2    Kick\n3    Ass?\ndtype: object"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "# Solution 1\n",
    "ser.map(lambda x: x.title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0     How\n1      To\n2    Kick\n3    Ass?\ndtype: object"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "# Solution 2\n",
    "ser.map(lambda x: x[0].upper() + x[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0     How\n1      To\n2    Kick\n3    Ass?\ndtype: object"
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "# Solution 3\n",
    "pd.Series([i.title() for i in ser])"
   ]
  },
  {
   "source": [
    "#### 19. How to calculate the number of characters in each word in a series?\n",
    "Difficulty Level: L2\n",
    "\n",
    "Input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    3\n1    2\n2    4\n3    4\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "ser.map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    3\n1    2\n2    4\n3    4\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "# Book Solution\n",
    "ser.map(lambda x: len(x))"
   ]
  },
  {
   "source": [
    "#### 20. How to compute difference of differences between consequtive numbers of a series?\n",
    "Difficulty Level: L1\n",
    "\n",
    "Difference of differences between the consequtive numbers of ser.\n",
    "\n",
    "Input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series([1, 3, 6, 10, 15, 21, 27, 35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "8"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "len(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[2, 3, 4, 5, 6, 6, 8]"
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "dif_ser = []\n",
    "for i in range(len(ser)-1):\n",
    "  dif_ser.append(ser[i+1]-ser[i])\n",
    "\n",
    "dif_ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[nan, 2.0, 3.0, 4.0, 5.0, 6.0, 6.0, 8.0]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[nan, nan, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0]"
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "# Solution\n",
    "print(ser.diff().tolist())\n",
    "ser.diff().diff().tolist()\n"
   ]
  },
  {
   "source": [
    "#### 21. How to convert a series of date-strings to a timeseries?\n",
    "Difficiulty Level: L2\n",
    "\n",
    "Input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0   2010-01-01 00:00:00\n1   2011-02-02 00:00:00\n2   2012-03-03 00:00:00\n3   2013-04-04 00:00:00\n4   2014-05-05 00:00:00\n5   2015-06-06 12:20:00\ndtype: datetime64[ns]"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "pd.to_datetime(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0   2010-01-01 00:00:00\n1   2011-02-02 00:00:00\n2   2012-03-03 00:00:00\n3   2013-04-04 00:00:00\n4   2014-05-05 00:00:00\n5   2015-06-06 12:20:00\ndtype: datetime64[ns]"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "# Solution 1\n",
    "from dateutil.parser import parse\n",
    "ser.map(lambda x: parse(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0   2010-01-01 00:00:00\n1   2011-02-02 00:00:00\n2   2012-03-03 00:00:00\n3   2013-04-04 00:00:00\n4   2014-05-05 00:00:00\n5   2015-06-06 12:20:00\ndtype: datetime64[ns]"
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "# Solution 2\n",
    "pd.to_datetime(ser)"
   ]
  },
  {
   "source": [
    "####  22. How to get the day of month, week number, day of year and day of week from a series of date strings?\n",
    "\n",
    "Difficiulty Level: L2\n",
    "\n",
    "Get the day of month, week number, day of year and day of week from ser.\n",
    "\n",
    "Input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "ser = pd.to_datetime(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0       Friday\n1    Wednesday\n2     Saturday\n3     Thursday\n4       Monday\n5     Saturday\ndtype: object"
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "ser.dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    4\n1    2\n2    5\n3    3\n4    0\n5    5\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "ser.dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    53\n1     5\n2     9\n3    14\n4    19\n5    23\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "ser.dt.week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0      1\n1     33\n2     63\n3     94\n4    125\n5    157\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "ser.dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    31\n1    28\n2    31\n3    30\n4    31\n5    30\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "ser.dt.daysinmonth"
   ]
  },
  {
   "source": [
    "#### 23. How to convert year-month string to dates corresponding to the 4th day of the month?\n",
    "Difficiulty Level: L2\n",
    "\n",
    "Change ser to dates that start with 4th of the respective months.\n",
    "\n",
    "Input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['Jan 2010', 'Feb 2011', 'Mar 2012'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0   2010-01-01\n1   2011-02-01\n2   2012-03-01\ndtype: datetime64[ns]"
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "ser = pd.to_datetime(ser)\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0   2010-01-04\n1   2011-02-04\n2   2012-03-04\ndtype: datetime64[ns]"
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "ser = ser.map(lambda x: x.replace(day=4))\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0   2010-01-04\n1   2011-02-04\n2   2012-03-04\ndtype: datetime64[ns]"
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "#Book solution\n",
    "\n",
    "# Solution 1\n",
    "from dateutil.parser import parse\n",
    "# Parse the date\n",
    "ser_ts = ser.map(lambda x: parse(x))\n",
    "\n",
    "# Construct date string with date as 4\n",
    "ser_datestr = ser_ts.dt.year.astype('str') + '-' + ser_ts.dt.month.astype('str') + '-' + '04'\n",
    "\n",
    "# Format it.\n",
    "[parse(i).strftime('%Y-%m-%d') for i in ser_datestr]\n",
    "\n",
    "# Solution 2\n",
    "ser.map(lambda x: parse('04 ' + x))"
   ]
  },
  {
   "source": [
    "#### 24. How to filter words that contain atleast 2 vowels from a series?\n",
    "Difficiulty Level: L3\n",
    "\n",
    "From ser, extract words that contain atleast 2 vowels.\n",
    "\n",
    "Input "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Apple', 'Orange', 'Money']\n"
    }
   ],
   "source": [
    "vowels = list('aeiou')\n",
    "l = []\n",
    "\n",
    "for word in ser.values:\n",
    "    count = 0\n",
    "    for char in word:\n",
    "        if (char.lower() in vowels):\n",
    "            count = count + 1\n",
    "            if count > 1:\n",
    "                l.append(word)\n",
    "                break\n",
    "               \n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Series([], dtype: object)"
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "#Book solution\n",
    "from collections import Counter\n",
    "mask = ser.map(lambda x: sum([Counter(x.lower()).get(i, 0) for i in list('aeiou')]) >= 2)\n",
    "ser[mask]"
   ]
  },
  {
   "source": [
    "#### 25. How to filter valid emails from a series?\n",
    "Difficiulty Level: L3\n",
    "\n",
    "Extract the valid emails from the series emails. The regex pattern for valid emails is provided as reference.\n",
    "\n",
    "Input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = pd.Series(['buying books at amazom.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com'])\n",
    "pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['rameses@egypt.com', 'matt@t.co', 'narendra@modi.com']"
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "import re as re \n",
    "[line for line in emails if re.match(pattern, line)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['rameses@egypt.com', 'matt@t.co', 'narendra@modi.com']"
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "# Solution 1 (as series of strings)\n",
    "import re\n",
    "pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'\n",
    "mask = emails.map(lambda x: bool(re.match(pattern, x)))\n",
    "emails[mask]\n",
    "\n",
    "# Solution 2 (as series of list)\n",
    "emails.str.findall(pattern, flags=re.IGNORECASE)\n",
    "\n",
    "# Solution 3 (as list)\n",
    "[x[0] for x in [re.findall(pattern, email) for email in emails] if len(x) > 0]"
   ]
  },
  {
   "source": [
    "#### 26. How to get the mean of a series grouped by another series?\n",
    "Difficiulty Level: L2\n",
    "\n",
    "Compute the mean of weights of each fruit.\n",
    "\n",
    "Input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n['banana', 'carrot', 'banana', 'carrot', 'carrot', 'banana', 'apple', 'banana', 'banana', 'apple']\n"
    }
   ],
   "source": [
    "fruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\n",
    "weights = pd.Series(np.linspace(1, 10, 10))\n",
    "print(weights.tolist())\n",
    "print(fruit.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"fuits\":fruit, \"weights\": weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         weights\nfuits           \napple   8.500000\nbanana  5.400000\ncarrot  3.666667",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>weights</th>\n    </tr>\n    <tr>\n      <th>fuits</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>apple</td>\n      <td>8.500000</td>\n    </tr>\n    <tr>\n      <td>banana</td>\n      <td>5.400000</td>\n    </tr>\n    <tr>\n      <td>carrot</td>\n      <td>3.666667</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "df.groupby('fuits').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "apple     8.500000\nbanana    5.400000\ncarrot    3.666667\ndtype: float64"
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "# Book Solution\n",
    "weights.groupby(fruit).mean()"
   ]
  },
  {
   "source": [
    "#### 27. How to compute the euclidean distance between two series?\n",
    "Difficiulty Level: L2\n",
    "\n",
    "Compute the euclidean distance between series (points) p and q, without using a packaged formula.\n",
    "\n",
    "Input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "q = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "18.16590212458495"
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "dist = (np.linalg.norm(p-q)) \n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "18.16590212458495"
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "# Solution \n",
    "sum((p - q)**2)**.5\n",
    "\n",
    "# Solution (using func)\n",
    "np.linalg.norm(p-q)"
   ]
  },
  {
   "source": [
    "#### 28. How to find all the local maxima (or peaks) in a numeric series?\n",
    "Difficiulty Level: L3\n",
    "\n",
    "Get the positions of peaks (values surrounded by smaller values on both sides) in ser.\n",
    "\n",
    "Input\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series([2, 10, 3, 4, 9, 10, 2, 7, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[1, 5, 7]"
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "source": [
    "[i for i,x in enumerate(ser) if (i!= 0 and i!=(len(ser)-1) and ser[i-1]< x >ser[i+1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1, 5, 7], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "# Book Solution\n",
    "dd = np.diff(np.sign(np.diff(ser)))\n",
    "peak_locs = np.where(dd == -2)[0] + 1\n",
    "peak_locs"
   ]
  },
  {
   "source": [
    "#### 29. How to replace missing spaces in a string with the least frequent character?\n",
    "Replace the spaces in my_str with the least frequent character.\n",
    "\n",
    "Difficiulty Level: L2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_str = 'dbc deb abed gade'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The least frequent character:  g\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'dbcgdebgabedggade'"
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "strings = pd.Series(list(my_str))\n",
    "char = strings.value_counts().argmin()\n",
    "print(\"The least frequent character: \", char)\n",
    "my_str.replace(\" \", char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "d    4\n     3\ne    3\nb    3\na    2\ng    1\nc    1\ndtype: int64\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'dbccdebcabedcgade'"
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "# Book Solution\n",
    "ser = pd.Series(list('dbc deb abed gade'))\n",
    "freq = ser.value_counts()\n",
    "print(freq)\n",
    "least_freq = freq.dropna().index[-1]\n",
    "\"\".join(ser.replace(' ', least_freq))"
   ]
  },
  {
   "source": [
    "#### 30. How to create a TimeSeries starting ‘2000-01-01’ and 10 weekends (saturdays) after that having random numbers as values?\n",
    "Difficiulty Level: L2\n",
    "\n",
    "Desired output"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "datetime.datetime(2000, 1, 8, 0, 0)"
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "starting = datetime(2000,1, 1)\n",
    "starting.strftime('%A')\n",
    "\n",
    "starting + timedelta(days=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2000-01-01    1\n2000-01-08    3\n2000-01-15    9\n2000-01-22    1\n2000-01-29    8\n2000-02-05    7\n2000-02-12    6\n2000-02-19    9\n2000-02-26    3\n2000-03-04    3\nFreq: W-SAT, dtype: int32"
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "# Solution\n",
    "ser = pd.Series(np.random.randint(1,10,10), pd.date_range('2000-01-01', periods=10, freq='W-SAT'))\n",
    "ser"
   ]
  },
  {
   "source": [
    "#### 31. How to fill an intermittent time series so all missing dates show up with values of previous non-missing date?\n",
    "Difficiulty Level: L2\n",
    "\n",
    "ser has missing dates and values. Make all missing dates appear and fill up with value from previous date.\n",
    "Input"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 115,
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-115-047641b3b483>, line 2)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-115-047641b3b483>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    Difficiulty Level: L2\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2000-01-01     1.0\n2000-01-03    10.0\n2000-01-06     3.0\n2000-01-08     NaN\ndtype: float64\n"
    }
   ],
   "source": [
    "ser = pd.Series([1,10,3,np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2000-01-01     2.0\n2000-01-02     NaN\n2000-01-03    13.0\n2000-01-04     NaN\n2000-01-05     NaN\n2000-01-06     9.0\n2000-01-07     NaN\n2000-01-08     NaN\ndtype: float64"
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "source": [
    "ser_2 = pd.Series(np.arange(1,9),index=pd.date_range('2000-01-01', periods=8))\n",
    "ser_2\n",
    "\n",
    "ser.add(ser_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2000-01-01     1.0\n2000-01-02     1.0\n2000-01-03    10.0\n2000-01-04    10.0\n2000-01-05    10.0\n2000-01-06     3.0\n2000-01-07     3.0\n2000-01-08     NaN\nFreq: D, dtype: float64"
     },
     "metadata": {},
     "execution_count": 118
    }
   ],
   "source": [
    "ser.resample('D').ffill()  # fill with previous value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2000-01-01     1.0\n2000-01-02    10.0\n2000-01-03    10.0\n2000-01-04     3.0\n2000-01-05     3.0\n2000-01-06     3.0\n2000-01-07     3.0\n2000-01-08     3.0\nFreq: D, dtype: float64"
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "source": [
    "# Alternatives\n",
    "ser.resample('D').bfill()  # fill with next value\n",
    "ser.resample('D').bfill().ffill()  # fill next else prev value"
   ]
  },
  {
   "source": [
    "#### 32. How to compute the autocorrelations of a numeric series?\n",
    "Difficiulty Level: L3\n",
    "\n",
    "Compute autocorrelations for the first 10 lags of ser. Find out which lag has the largest correlation.\n",
    "\n",
    "Input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ 7.49440883e+00, -3.43721898e-01, -1.27224638e+00, -2.20958620e-01,\n        6.30002054e-01,  1.87792836e+01,  1.78416227e+01, -1.24189356e-02,\n       -1.48267005e+01,  1.16533737e+01,  2.34791154e+00,  1.48458382e+00,\n        6.33819809e-01,  7.74608932e+00,  1.13721415e+01, -8.02751516e+00,\n       -1.61127559e+01,  9.32525895e+00,  9.29251786e+00, -1.41922496e+01])"
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "np.random.normal(1, 10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0     17.726222\n1    -10.064616\n2      5.825261\n3     -0.992450\n4     10.006880\n5     19.711934\n6     -0.127830\n7      4.527033\n8     -3.640644\n9     16.862946\n10    -1.017060\n11    18.252008\n12    17.935731\n13    20.229497\n14    10.909573\n15    12.822080\n16     7.814999\n17    22.882891\n18    20.935060\n19    39.014667\ndtype: float64"
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "source": [
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1.0\n0.16\n0.44\n-0.17\n0.19\n0.24\n0.37\n0.42\n0.2\n0.08\n-0.09\n"
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    print(ser.autocorr(i).round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.16, 0.44, -0.17, 0.19, 0.24, 0.37, 0.42, 0.2, 0.08, -0.09]\nLag having highest correlation:  2\n"
    }
   ],
   "source": [
    "# Solution\n",
    "autocorrelations = [ser.autocorr(i).round(2) for i in range(11)]\n",
    "print(autocorrelations[1:])\n",
    "print('Lag having highest correlation: ', np.argmax(np.abs(autocorrelations[1:]))+1)"
   ]
  },
  {
   "source": [
    "#### 33. How to import only every nth row from a csv file to create a dataframe?\n",
    "Difficiulty Level: L2\n",
    "\n",
    "Import every 50th row of BostonHousing dataset as a dataframe."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "boston = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ".. _boston_dataset:\n\nBoston house prices dataset\n---------------------------\n\n**Data Set Characteristics:**  \n\n    :Number of Instances: 506 \n\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n\n    :Attribute Information (in order):\n        - CRIM     per capita crime rate by town\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n        - INDUS    proportion of non-retail business acres per town\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n        - NOX      nitric oxides concentration (parts per 10 million)\n        - RM       average number of rooms per dwelling\n        - AGE      proportion of owner-occupied units built prior to 1940\n        - DIS      weighted distances to five Boston employment centres\n        - RAD      index of accessibility to radial highways\n        - TAX      full-value property-tax rate per $10,000\n        - PTRATIO  pupil-teacher ratio by town\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n        - LSTAT    % lower status of the population\n        - MEDV     Median value of owner-occupied homes in $1000's\n\n    :Missing Attribute Values: None\n\n    :Creator: Harrison, D. and Rubinfeld, D.L.\n\nThis is a copy of UCI ML housing dataset.\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n\n\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\nprices and the demand for clean air', J. Environ. Economics & Management,\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\npages 244-261 of the latter.\n\nThe Boston house-price data has been used in many machine learning papers that address regression\nproblems.   \n     \n.. topic:: References\n\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n\n"
    }
   ],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'bos' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-95f768775ee2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mbos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bos' is not defined"
     ]
    }
   ],
   "source": [
    "print(bos.iloc[50])\n",
    "bos.iloc[50].index\n",
    "bos.iloc[50].values\n",
    "bos.iloc[50].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bos = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "bos_50 = pd.DataFrame(columns = boston.feature_names)\n",
    "\n",
    "for idx in bos.index:\n",
    "    if (idx % 50 == 0):\n",
    "        bos_50 = bos_50.append(bos.iloc[idx].to_dict(), ignore_index=True)\n",
    "bos_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "source": [
    "bos_50.iloc[1].all() == bos.iloc[50].all()\n",
    "#bos_50.iloc[2].all() == bos.iloc[100].all()"
   ]
  },
  {
   "source": [
    "# Solution 1: Use chunks and for-loop\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', chunksize=50)\n",
    "df2 = pd.DataFrame()\n",
    "for chunk in df:\n",
    "    df2 = df2.append(chunk.iloc[0,:])\n",
    "\n",
    "\n",
    "# Solution 2: Use chunks and list comprehension\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', chunksize=50)\n",
    "df2 = pd.concat([chunk.iloc[0] for chunk in df], axis=1)\n",
    "df2 = df2.transpose()\n",
    "\n",
    "# Solution 3: Use csv reader\n",
    "\n",
    "import csv          \n",
    "with open('BostonHousing.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    out = []\n",
    "    for i, row in enumerate(reader):\n",
    "        if i%50 == 0:\n",
    "            out.append(row)\n",
    "\n",
    "df2 = pd.DataFrame(out[1:], columns=out[0])\n",
    "print(df2.head())"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 130,
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'BostonHousing.csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-130-db16f3e550bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'BostonHousing.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'BostonHousing.csv'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 34. How to change column values when importing csv to a dataframe?\n",
    "Difficulty Level: L2\n",
    "\n",
    "Import the boston housing dataset, but while importing change the 'medv' (median house value) column so that values < 25 becomes ‘Low’ and > 25 becomes ‘High’.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n\n        b  lstat  medv  \n0  396.90   4.98   Low  \n1  396.90   9.14   Low  \n2  392.83   4.03  High  \n3  394.63   2.94  High  \n4  396.90   5.33  High  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>crim</th>\n      <th>zn</th>\n      <th>indus</th>\n      <th>chas</th>\n      <th>nox</th>\n      <th>rm</th>\n      <th>age</th>\n      <th>dis</th>\n      <th>rad</th>\n      <th>tax</th>\n      <th>ptratio</th>\n      <th>b</th>\n      <th>lstat</th>\n      <th>medv</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.00632</td>\n      <td>18.0</td>\n      <td>2.31</td>\n      <td>0</td>\n      <td>0.538</td>\n      <td>6.575</td>\n      <td>65.2</td>\n      <td>4.0900</td>\n      <td>1</td>\n      <td>296</td>\n      <td>15.3</td>\n      <td>396.90</td>\n      <td>4.98</td>\n      <td>Low</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.02731</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0</td>\n      <td>0.469</td>\n      <td>6.421</td>\n      <td>78.9</td>\n      <td>4.9671</td>\n      <td>2</td>\n      <td>242</td>\n      <td>17.8</td>\n      <td>396.90</td>\n      <td>9.14</td>\n      <td>Low</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.02729</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0</td>\n      <td>0.469</td>\n      <td>7.185</td>\n      <td>61.1</td>\n      <td>4.9671</td>\n      <td>2</td>\n      <td>242</td>\n      <td>17.8</td>\n      <td>392.83</td>\n      <td>4.03</td>\n      <td>High</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.03237</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0</td>\n      <td>0.458</td>\n      <td>6.998</td>\n      <td>45.8</td>\n      <td>6.0622</td>\n      <td>3</td>\n      <td>222</td>\n      <td>18.7</td>\n      <td>394.63</td>\n      <td>2.94</td>\n      <td>High</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.06905</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0</td>\n      <td>0.458</td>\n      <td>7.147</td>\n      <td>54.2</td>\n      <td>6.0622</td>\n      <td>3</td>\n      <td>222</td>\n      <td>18.7</td>\n      <td>396.90</td>\n      <td>5.33</td>\n      <td>High</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 132
    }
   ],
   "source": [
    "# Solution 1: Using converter parameter\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', \n",
    "                 converters={'medv': lambda x: 'High' if float(x) > 25 else 'Low'})\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "#### 35. How to create a dataframe with rows as strides from a given series?\n",
    "Difficiulty Level: L3"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = pd.Series(range(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 0,  1,  2,  3],\n       [ 2,  3,  4,  5],\n       [ 4,  5,  6,  7],\n       [ 6,  7,  8,  9],\n       [ 8,  9, 10, 11],\n       [10, 11, 12, 13]], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "source": [
    "def gen_strides(a, stride_len=5, window_len=5):\n",
    "    n_strides = ((a.size-window_len)//stride_len) + 1\n",
    "    return np.array([a[s:(s+window_len)] for s in np.arange(0, a.size, stride_len)[:n_strides]])\n",
    "\n",
    "gen_strides(L, stride_len=2, window_len=4)"
   ]
  },
  {
   "source": [
    "#### 36. How to import only specified columns from a csv file?\n",
    "Difficulty Level: L1\n",
    "\n",
    "Import ‘crim’ and ‘medv’ columns of the BostonHousing dataset as a dataframe."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      crim  medv\n0  0.00632  24.0\n1  0.02731  21.6\n2  0.02729  34.7\n3  0.03237  33.4\n4  0.06905  36.2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>crim</th>\n      <th>medv</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.00632</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.02731</td>\n      <td>21.6</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.02729</td>\n      <td>34.7</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.03237</td>\n      <td>33.4</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.06905</td>\n      <td>36.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', \n",
    "                usecols=['crim','medv'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "      crim  medv\n0  0.00632  24.0\n1  0.02731  21.6\n2  0.02729  34.7\n3  0.03237  33.4\n4  0.06905  36.2\n"
    }
   ],
   "source": [
    "# Book solution\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', usecols=['crim', 'medv'])\n",
    "print(df.head())"
   ]
  },
  {
   "source": [
    "#### 37. How to get the nrows, ncolumns, datatype, summary stats of each column of a dataframe? Also get the array and list equivalent.\n",
    "Difficulty Level: L2\n",
    "\n",
    "Get the number of rows, columns, datatype and summary statistics of each column of the Cars93 dataset. Also get the numpy array and list equivalent of the dataframe."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Rows 93\nColumns 27\n"
    }
   ],
   "source": [
    "df.shape\n",
    "print('Rows',df.shape[0])\n",
    "print('Columns',df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 93 entries, 0 to 92\nData columns (total 27 columns):\nManufacturer          89 non-null object\nModel                 92 non-null object\nType                  90 non-null object\nMin.Price             86 non-null float64\nPrice                 91 non-null float64\nMax.Price             88 non-null float64\nMPG.city              84 non-null float64\nMPG.highway           91 non-null float64\nAirBags               87 non-null object\nDriveTrain            86 non-null object\nCylinders             88 non-null object\nEngineSize            91 non-null float64\nHorsepower            86 non-null float64\nRPM                   90 non-null float64\nRev.per.mile          87 non-null float64\nMan.trans.avail       88 non-null object\nFuel.tank.capacity    85 non-null float64\nPassengers            91 non-null float64\nLength                89 non-null float64\nWheelbase             92 non-null float64\nWidth                 87 non-null float64\nTurn.circle           88 non-null float64\nRear.seat.room        89 non-null float64\nLuggage.room          74 non-null float64\nWeight                86 non-null float64\nOrigin                88 non-null object\nMake                  90 non-null object\ndtypes: float64(18), object(9)\nmemory usage: 19.7+ KB\n"
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       Min.Price      Price  Max.Price   MPG.city  MPG.highway  EngineSize  \\\ncount  86.000000  91.000000  88.000000  84.000000    91.000000   91.000000   \nmean   17.118605  19.616484  21.459091  22.404762    29.065934    2.658242   \nstd     8.828290   9.724280  10.696563   5.841520     5.370293    1.045845   \nmin     6.700000   7.400000   7.900000  15.000000    20.000000    1.000000   \n25%    10.825000  12.350000  14.575000  18.000000    26.000000    1.800000   \n50%    14.600000  17.700000  19.150000  21.000000    28.000000    2.300000   \n75%    20.250000  23.500000  24.825000  25.000000    31.000000    3.250000   \nmax    45.400000  61.900000  80.000000  46.000000    50.000000    5.700000   \n\n       Horsepower          RPM  Rev.per.mile  Fuel.tank.capacity  Passengers  \\\ncount   86.000000    90.000000     87.000000           85.000000   91.000000   \nmean   144.000000  5276.666667   2355.000000           16.683529    5.076923   \nstd     53.455204   605.554811    486.916616            3.375748    1.045953   \nmin     55.000000  3800.000000   1320.000000            9.200000    2.000000   \n25%    100.750000  4800.000000   2017.500000           14.500000    4.000000   \n50%    140.000000  5200.000000   2360.000000           16.500000    5.000000   \n75%    170.000000  5787.500000   2565.000000           19.000000    6.000000   \nmax    300.000000  6500.000000   3755.000000           27.000000    8.000000   \n\n           Length   Wheelbase      Width  Turn.circle  Rear.seat.room  \\\ncount   89.000000   92.000000  87.000000    88.000000       89.000000   \nmean   182.865169  103.956522  69.448276    38.954545       27.853933   \nstd     14.792651    6.856317   3.778023     3.304157        3.018129   \nmin    141.000000   90.000000  60.000000    32.000000       19.000000   \n25%    174.000000   98.000000  67.000000    36.000000       26.000000   \n50%    181.000000  103.000000  69.000000    39.000000       27.500000   \n75%    192.000000  110.000000  72.000000    42.000000       30.000000   \nmax    219.000000  119.000000  78.000000    45.000000       36.000000   \n\n       Luggage.room       Weight  \ncount     74.000000    86.000000  \nmean      13.986486  3104.593023  \nstd        3.120824   600.129993  \nmin        6.000000  1695.000000  \n25%       12.000000  2647.500000  \n50%       14.000000  3085.000000  \n75%       16.000000  3567.500000  \nmax       22.000000  4105.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Min.Price</th>\n      <th>Price</th>\n      <th>Max.Price</th>\n      <th>MPG.city</th>\n      <th>MPG.highway</th>\n      <th>EngineSize</th>\n      <th>Horsepower</th>\n      <th>RPM</th>\n      <th>Rev.per.mile</th>\n      <th>Fuel.tank.capacity</th>\n      <th>Passengers</th>\n      <th>Length</th>\n      <th>Wheelbase</th>\n      <th>Width</th>\n      <th>Turn.circle</th>\n      <th>Rear.seat.room</th>\n      <th>Luggage.room</th>\n      <th>Weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>count</td>\n      <td>86.000000</td>\n      <td>91.000000</td>\n      <td>88.000000</td>\n      <td>84.000000</td>\n      <td>91.000000</td>\n      <td>91.000000</td>\n      <td>86.000000</td>\n      <td>90.000000</td>\n      <td>87.000000</td>\n      <td>85.000000</td>\n      <td>91.000000</td>\n      <td>89.000000</td>\n      <td>92.000000</td>\n      <td>87.000000</td>\n      <td>88.000000</td>\n      <td>89.000000</td>\n      <td>74.000000</td>\n      <td>86.000000</td>\n    </tr>\n    <tr>\n      <td>mean</td>\n      <td>17.118605</td>\n      <td>19.616484</td>\n      <td>21.459091</td>\n      <td>22.404762</td>\n      <td>29.065934</td>\n      <td>2.658242</td>\n      <td>144.000000</td>\n      <td>5276.666667</td>\n      <td>2355.000000</td>\n      <td>16.683529</td>\n      <td>5.076923</td>\n      <td>182.865169</td>\n      <td>103.956522</td>\n      <td>69.448276</td>\n      <td>38.954545</td>\n      <td>27.853933</td>\n      <td>13.986486</td>\n      <td>3104.593023</td>\n    </tr>\n    <tr>\n      <td>std</td>\n      <td>8.828290</td>\n      <td>9.724280</td>\n      <td>10.696563</td>\n      <td>5.841520</td>\n      <td>5.370293</td>\n      <td>1.045845</td>\n      <td>53.455204</td>\n      <td>605.554811</td>\n      <td>486.916616</td>\n      <td>3.375748</td>\n      <td>1.045953</td>\n      <td>14.792651</td>\n      <td>6.856317</td>\n      <td>3.778023</td>\n      <td>3.304157</td>\n      <td>3.018129</td>\n      <td>3.120824</td>\n      <td>600.129993</td>\n    </tr>\n    <tr>\n      <td>min</td>\n      <td>6.700000</td>\n      <td>7.400000</td>\n      <td>7.900000</td>\n      <td>15.000000</td>\n      <td>20.000000</td>\n      <td>1.000000</td>\n      <td>55.000000</td>\n      <td>3800.000000</td>\n      <td>1320.000000</td>\n      <td>9.200000</td>\n      <td>2.000000</td>\n      <td>141.000000</td>\n      <td>90.000000</td>\n      <td>60.000000</td>\n      <td>32.000000</td>\n      <td>19.000000</td>\n      <td>6.000000</td>\n      <td>1695.000000</td>\n    </tr>\n    <tr>\n      <td>25%</td>\n      <td>10.825000</td>\n      <td>12.350000</td>\n      <td>14.575000</td>\n      <td>18.000000</td>\n      <td>26.000000</td>\n      <td>1.800000</td>\n      <td>100.750000</td>\n      <td>4800.000000</td>\n      <td>2017.500000</td>\n      <td>14.500000</td>\n      <td>4.000000</td>\n      <td>174.000000</td>\n      <td>98.000000</td>\n      <td>67.000000</td>\n      <td>36.000000</td>\n      <td>26.000000</td>\n      <td>12.000000</td>\n      <td>2647.500000</td>\n    </tr>\n    <tr>\n      <td>50%</td>\n      <td>14.600000</td>\n      <td>17.700000</td>\n      <td>19.150000</td>\n      <td>21.000000</td>\n      <td>28.000000</td>\n      <td>2.300000</td>\n      <td>140.000000</td>\n      <td>5200.000000</td>\n      <td>2360.000000</td>\n      <td>16.500000</td>\n      <td>5.000000</td>\n      <td>181.000000</td>\n      <td>103.000000</td>\n      <td>69.000000</td>\n      <td>39.000000</td>\n      <td>27.500000</td>\n      <td>14.000000</td>\n      <td>3085.000000</td>\n    </tr>\n    <tr>\n      <td>75%</td>\n      <td>20.250000</td>\n      <td>23.500000</td>\n      <td>24.825000</td>\n      <td>25.000000</td>\n      <td>31.000000</td>\n      <td>3.250000</td>\n      <td>170.000000</td>\n      <td>5787.500000</td>\n      <td>2565.000000</td>\n      <td>19.000000</td>\n      <td>6.000000</td>\n      <td>192.000000</td>\n      <td>110.000000</td>\n      <td>72.000000</td>\n      <td>42.000000</td>\n      <td>30.000000</td>\n      <td>16.000000</td>\n      <td>3567.500000</td>\n    </tr>\n    <tr>\n      <td>max</td>\n      <td>45.400000</td>\n      <td>61.900000</td>\n      <td>80.000000</td>\n      <td>46.000000</td>\n      <td>50.000000</td>\n      <td>5.700000</td>\n      <td>300.000000</td>\n      <td>6500.000000</td>\n      <td>3755.000000</td>\n      <td>27.000000</td>\n      <td>8.000000</td>\n      <td>219.000000</td>\n      <td>119.000000</td>\n      <td>78.000000</td>\n      <td>45.000000</td>\n      <td>36.000000</td>\n      <td>22.000000</td>\n      <td>4105.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 140
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[array(['Acura', 'Integra', 'Small', 12.9, 15.9, 18.8, 25.0, 31.0, 'None',\n        'Front', '4', 1.8, 140.0, 6300.0, 2890.0, 'Yes', 13.2, 5.0, 177.0,\n        102.0, 68.0, 37.0, 26.5, nan, 2705.0, 'non-USA', 'Acura Integra'],\n       dtype=object),\n array([nan, 'Legend', 'Midsize', 29.2, 33.9, 38.7, 18.0, 25.0,\n        'Driver & Passenger', 'Front', '6', 3.2, 200.0, 5500.0, 2335.0,\n        'Yes', 18.0, 5.0, 195.0, 115.0, 71.0, 38.0, 30.0, 15.0, 3560.0,\n        'non-USA', 'Acura Legend'], dtype=object),\n array(['Audi', '90', 'Compact', 25.9, 29.1, 32.3, 20.0, 26.0,\n        'Driver only', 'Front', '6', 2.8, 172.0, 5500.0, 2280.0, 'Yes',\n        16.9, 5.0, 180.0, 102.0, 67.0, 37.0, 28.0, 14.0, 3375.0, 'non-USA',\n        'Audi 90'], dtype=object),\n array(['Audi', '100', 'Midsize', nan, 37.7, 44.6, 19.0, 26.0,\n        'Driver & Passenger', nan, '6', nan, 172.0, 5500.0, 2535.0, nan,\n        21.1, 6.0, 193.0, 106.0, nan, 37.0, 31.0, 17.0, 3405.0, 'non-USA',\n        'Audi 100'], dtype=object),\n array(['BMW', '535i', 'Midsize', nan, 30.0, nan, 22.0, 30.0, nan, 'Rear',\n        '4', 3.5, 208.0, 5700.0, 2545.0, 'Yes', 21.1, 4.0, 186.0, 109.0,\n        69.0, 39.0, 27.0, 13.0, 3640.0, 'non-USA', 'BMW 535i'],\n       dtype=object),\n array(['Buick', 'Century', 'Midsize', 14.2, 15.7, 17.3, 22.0, 31.0,\n        'Driver only', nan, '4', 2.2, 110.0, 5200.0, 2565.0, 'No', 16.4,\n        6.0, 189.0, 105.0, 69.0, 41.0, 28.0, 16.0, nan, 'USA',\n        'Buick Century'], dtype=object)]"
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "source": [
    "arr = df.values\n",
    "list(arr)[:6]"
   ]
  },
  {
   "source": [
    "#### 38. How to extract the row and column number of a particular cell with given criterion?\n",
    "Difficulty Level: L1\n",
    "\n",
    "Input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Index(['Manufacturer', 'Model', 'Type', 'Min.Price', 'Price', 'Max.Price',\n       'MPG.city', 'MPG.highway', 'AirBags', 'DriveTrain', 'Cylinders',\n       'EngineSize', 'Horsepower', 'RPM', 'Rev.per.mile', 'Man.trans.avail',\n       'Fuel.tank.capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n       'Turn.circle', 'Rear.seat.room', 'Luggage.room', 'Weight', 'Origin',\n       'Make'],\n      dtype='object')\n"
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "source": [
    "Which manufacturer, model and type has the highest Price? What is the row and column number of the cell with the highest Price value?"
   ],
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Price max: 61.9\nIndex price_max: 58 \n\nManufacturer               Mercedes-Benz\nModel                               300E\nType                             Midsize\nMin.Price                           43.8\nPrice                               61.9\nMax.Price                             80\nMPG.city                              19\nMPG.highway                           25\nAirBags               Driver & Passenger\nDriveTrain                          Rear\nCylinders                              6\nEngineSize                           3.2\nHorsepower                           217\nRPM                                 5500\nRev.per.mile                        2220\nMan.trans.avail                       No\nFuel.tank.capacity                  18.5\nPassengers                             5\nLength                               NaN\nWheelbase                            110\nWidth                                 69\nTurn.circle                           37\nRear.seat.room                       NaN\nLuggage.room                          15\nWeight                              3525\nOrigin                           non-USA\nMake                  Mercedes-Benz 300E\nName: 58, dtype: object \n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Manufacturer    Mercedes-Benz\nModel                    300E\nType                  Midsize\nName: 58, dtype: object"
     },
     "metadata": {},
     "execution_count": 144
    }
   ],
   "source": [
    "indx = df['Price'].argmax()\n",
    "print(\"Price max:\", df['Price'].max())\n",
    "print(\"Index price_max:\",indx,\"\\n\")\n",
    "\n",
    "print(df.iloc[indx],\"\\n\")\n",
    "\n",
    "df.loc[:,['Manufacturer', 'Model', 'Type']].iloc[indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "61.9"
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "source": [
    "# Web Solution\n",
    "# Get Manufacturer with highest price\n",
    "df.loc[df.Price == np.max(df.Price), ['Manufacturer', 'Model', 'Type']]\n",
    "\n",
    "# Get Row and Column number\n",
    "row, col = np.where(df.values == np.max(df.Price))\n",
    "\n",
    "# Get the value\n",
    "df.iat[row[0], col[0]]\n",
    "df.iloc[row[0], col[0]]\n",
    "\n",
    "# Alternates\n",
    "df.at[row[0], 'Price']\n",
    "df.get_value(row[0], 'Price')\n",
    "\n",
    "# The difference between `iat` - `iloc` vs `at` - `loc` is:\n",
    "# `iat` snd `iloc` accepts row and column numbers. \n",
    "# Whereas `at` and `loc` accepts index and column names."
   ]
  },
  {
   "source": [
    "#### 39. How to rename a specific columns in a dataframe?\n",
    "Difficulty Level: L2\n",
    "\n",
    "Rename the column Type as CarType in df and replace the ‘.’ in column names with ‘_’.\n",
    "\n",
    "Input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  Manufacturer    Model     Type  Min.Price  Price  Max.Price  MPG.city  \\\n0        Acura  Integra    Small       12.9   15.9       18.8      25.0   \n1          NaN   Legend  Midsize       29.2   33.9       38.7      18.0   \n2         Audi       90  Compact       25.9   29.1       32.3      20.0   \n3         Audi      100  Midsize        NaN   37.7       44.6      19.0   \n4          BMW     535i  Midsize        NaN   30.0        NaN      22.0   \n\n   MPG.highway             AirBags DriveTrain  ... Passengers  Length  \\\n0         31.0                None      Front  ...        5.0   177.0   \n1         25.0  Driver & Passenger      Front  ...        5.0   195.0   \n2         26.0         Driver only      Front  ...        5.0   180.0   \n3         26.0  Driver & Passenger        NaN  ...        6.0   193.0   \n4         30.0                 NaN       Rear  ...        4.0   186.0   \n\n   Wheelbase  Width  Turn.circle Rear.seat.room  Luggage.room  Weight  \\\n0      102.0   68.0         37.0           26.5           NaN  2705.0   \n1      115.0   71.0         38.0           30.0          15.0  3560.0   \n2      102.0   67.0         37.0           28.0          14.0  3375.0   \n3      106.0    NaN         37.0           31.0          17.0  3405.0   \n4      109.0   69.0         39.0           27.0          13.0  3640.0   \n\n    Origin           Make  \n0  non-USA  Acura Integra  \n1  non-USA   Acura Legend  \n2  non-USA        Audi 90  \n3  non-USA       Audi 100  \n4  non-USA       BMW 535i  \n\n[5 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Manufacturer</th>\n      <th>Model</th>\n      <th>Type</th>\n      <th>Min.Price</th>\n      <th>Price</th>\n      <th>Max.Price</th>\n      <th>MPG.city</th>\n      <th>MPG.highway</th>\n      <th>AirBags</th>\n      <th>DriveTrain</th>\n      <th>...</th>\n      <th>Passengers</th>\n      <th>Length</th>\n      <th>Wheelbase</th>\n      <th>Width</th>\n      <th>Turn.circle</th>\n      <th>Rear.seat.room</th>\n      <th>Luggage.room</th>\n      <th>Weight</th>\n      <th>Origin</th>\n      <th>Make</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>Acura</td>\n      <td>Integra</td>\n      <td>Small</td>\n      <td>12.9</td>\n      <td>15.9</td>\n      <td>18.8</td>\n      <td>25.0</td>\n      <td>31.0</td>\n      <td>None</td>\n      <td>Front</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>177.0</td>\n      <td>102.0</td>\n      <td>68.0</td>\n      <td>37.0</td>\n      <td>26.5</td>\n      <td>NaN</td>\n      <td>2705.0</td>\n      <td>non-USA</td>\n      <td>Acura Integra</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>NaN</td>\n      <td>Legend</td>\n      <td>Midsize</td>\n      <td>29.2</td>\n      <td>33.9</td>\n      <td>38.7</td>\n      <td>18.0</td>\n      <td>25.0</td>\n      <td>Driver &amp; Passenger</td>\n      <td>Front</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>195.0</td>\n      <td>115.0</td>\n      <td>71.0</td>\n      <td>38.0</td>\n      <td>30.0</td>\n      <td>15.0</td>\n      <td>3560.0</td>\n      <td>non-USA</td>\n      <td>Acura Legend</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>Audi</td>\n      <td>90</td>\n      <td>Compact</td>\n      <td>25.9</td>\n      <td>29.1</td>\n      <td>32.3</td>\n      <td>20.0</td>\n      <td>26.0</td>\n      <td>Driver only</td>\n      <td>Front</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>180.0</td>\n      <td>102.0</td>\n      <td>67.0</td>\n      <td>37.0</td>\n      <td>28.0</td>\n      <td>14.0</td>\n      <td>3375.0</td>\n      <td>non-USA</td>\n      <td>Audi 90</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>Audi</td>\n      <td>100</td>\n      <td>Midsize</td>\n      <td>NaN</td>\n      <td>37.7</td>\n      <td>44.6</td>\n      <td>19.0</td>\n      <td>26.0</td>\n      <td>Driver &amp; Passenger</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>6.0</td>\n      <td>193.0</td>\n      <td>106.0</td>\n      <td>NaN</td>\n      <td>37.0</td>\n      <td>31.0</td>\n      <td>17.0</td>\n      <td>3405.0</td>\n      <td>non-USA</td>\n      <td>Audi 100</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>BMW</td>\n      <td>535i</td>\n      <td>Midsize</td>\n      <td>NaN</td>\n      <td>30.0</td>\n      <td>NaN</td>\n      <td>22.0</td>\n      <td>30.0</td>\n      <td>NaN</td>\n      <td>Rear</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>186.0</td>\n      <td>109.0</td>\n      <td>69.0</td>\n      <td>39.0</td>\n      <td>27.0</td>\n      <td>13.0</td>\n      <td>3640.0</td>\n      <td>non-USA</td>\n      <td>BMW 535i</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 146
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  Manufacturer    Model  CarType  Min_Price  Price  Max_Price  MPG_city  \\\n0        Acura  Integra    Small       12.9   15.9       18.8      25.0   \n1          NaN   Legend  Midsize       29.2   33.9       38.7      18.0   \n2         Audi       90  Compact       25.9   29.1       32.3      20.0   \n3         Audi      100  Midsize        NaN   37.7       44.6      19.0   \n4          BMW     535i  Midsize        NaN   30.0        NaN      22.0   \n\n   MPG_highway             AirBags DriveTrain  ... Passengers  Length  \\\n0         31.0                None      Front  ...        5.0   177.0   \n1         25.0  Driver & Passenger      Front  ...        5.0   195.0   \n2         26.0         Driver only      Front  ...        5.0   180.0   \n3         26.0  Driver & Passenger        NaN  ...        6.0   193.0   \n4         30.0                 NaN       Rear  ...        4.0   186.0   \n\n   Wheelbase  Width  Turn_circle Rear_seat_room  Luggage_room  Weight  \\\n0      102.0   68.0         37.0           26.5           NaN  2705.0   \n1      115.0   71.0         38.0           30.0          15.0  3560.0   \n2      102.0   67.0         37.0           28.0          14.0  3375.0   \n3      106.0    NaN         37.0           31.0          17.0  3405.0   \n4      109.0   69.0         39.0           27.0          13.0  3640.0   \n\n    Origin           Make  \n0  non-USA  Acura Integra  \n1  non-USA   Acura Legend  \n2  non-USA        Audi 90  \n3  non-USA       Audi 100  \n4  non-USA       BMW 535i  \n\n[5 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Manufacturer</th>\n      <th>Model</th>\n      <th>CarType</th>\n      <th>Min_Price</th>\n      <th>Price</th>\n      <th>Max_Price</th>\n      <th>MPG_city</th>\n      <th>MPG_highway</th>\n      <th>AirBags</th>\n      <th>DriveTrain</th>\n      <th>...</th>\n      <th>Passengers</th>\n      <th>Length</th>\n      <th>Wheelbase</th>\n      <th>Width</th>\n      <th>Turn_circle</th>\n      <th>Rear_seat_room</th>\n      <th>Luggage_room</th>\n      <th>Weight</th>\n      <th>Origin</th>\n      <th>Make</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>Acura</td>\n      <td>Integra</td>\n      <td>Small</td>\n      <td>12.9</td>\n      <td>15.9</td>\n      <td>18.8</td>\n      <td>25.0</td>\n      <td>31.0</td>\n      <td>None</td>\n      <td>Front</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>177.0</td>\n      <td>102.0</td>\n      <td>68.0</td>\n      <td>37.0</td>\n      <td>26.5</td>\n      <td>NaN</td>\n      <td>2705.0</td>\n      <td>non-USA</td>\n      <td>Acura Integra</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>NaN</td>\n      <td>Legend</td>\n      <td>Midsize</td>\n      <td>29.2</td>\n      <td>33.9</td>\n      <td>38.7</td>\n      <td>18.0</td>\n      <td>25.0</td>\n      <td>Driver &amp; Passenger</td>\n      <td>Front</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>195.0</td>\n      <td>115.0</td>\n      <td>71.0</td>\n      <td>38.0</td>\n      <td>30.0</td>\n      <td>15.0</td>\n      <td>3560.0</td>\n      <td>non-USA</td>\n      <td>Acura Legend</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>Audi</td>\n      <td>90</td>\n      <td>Compact</td>\n      <td>25.9</td>\n      <td>29.1</td>\n      <td>32.3</td>\n      <td>20.0</td>\n      <td>26.0</td>\n      <td>Driver only</td>\n      <td>Front</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>180.0</td>\n      <td>102.0</td>\n      <td>67.0</td>\n      <td>37.0</td>\n      <td>28.0</td>\n      <td>14.0</td>\n      <td>3375.0</td>\n      <td>non-USA</td>\n      <td>Audi 90</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>Audi</td>\n      <td>100</td>\n      <td>Midsize</td>\n      <td>NaN</td>\n      <td>37.7</td>\n      <td>44.6</td>\n      <td>19.0</td>\n      <td>26.0</td>\n      <td>Driver &amp; Passenger</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>6.0</td>\n      <td>193.0</td>\n      <td>106.0</td>\n      <td>NaN</td>\n      <td>37.0</td>\n      <td>31.0</td>\n      <td>17.0</td>\n      <td>3405.0</td>\n      <td>non-USA</td>\n      <td>Audi 100</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>BMW</td>\n      <td>535i</td>\n      <td>Midsize</td>\n      <td>NaN</td>\n      <td>30.0</td>\n      <td>NaN</td>\n      <td>22.0</td>\n      <td>30.0</td>\n      <td>NaN</td>\n      <td>Rear</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>186.0</td>\n      <td>109.0</td>\n      <td>69.0</td>\n      <td>39.0</td>\n      <td>27.0</td>\n      <td>13.0</td>\n      <td>3640.0</td>\n      <td>non-USA</td>\n      <td>BMW 535i</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 157
    }
   ],
   "source": [
    "for name_col in df.columns:\n",
    "    if (name_col == 'Type'):\n",
    "        df =df.rename(columns={name_col:'Cartype'})\n",
    "        continue\n",
    "    if (\".\" in name_col):\n",
    "        df = df.rename(columns={name_col: name_col.replace('.','_')})\n",
    "        continue\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['Manufacturer', 'Model', 'Type', 'Min.Price', 'Price', 'Max.Price',\n       'MPG.city', 'MPG.highway', 'AirBags', 'DriveTrain', 'Cylinders',\n       'EngineSize', 'Horsepower', 'RPM', 'Rev.per.mile', 'Man.trans.avail',\n       'Fuel.tank.capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n       'Turn.circle', 'Rear.seat.room', 'Luggage.room', 'Weight', 'Origin',\n       'Make'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 148
    }
   ],
   "source": [
    "#Before\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['Manufacturer', 'Model', 'Cartype', 'Min_Price', 'Price', 'Max_Price',\n       'MPG_city', 'MPG_highway', 'AirBags', 'DriveTrain', 'Cylinders',\n       'EngineSize', 'Horsepower', 'RPM', 'Rev_per_mile', 'Man_trans_avail',\n       'Fuel_tank_capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n       'Turn_circle', 'Rear_seat_room', 'Luggage_room', 'Weight', 'Origin',\n       'Make'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 154
    }
   ],
   "source": [
    "#After\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Index(['Manufacturer', 'Model', 'CarType', 'Min_Price', 'Price', 'Max_Price',\n       'MPG_city', 'MPG_highway', 'AirBags', 'DriveTrain', 'Cylinders',\n       'EngineSize', 'Horsepower', 'RPM', 'Rev_per_mile', 'Man_trans_avail',\n       'Fuel_tank_capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n       'Turn_circle', 'Rear_seat_room', 'Luggage_room', 'Weight', 'Origin',\n       'Make'],\n      dtype='object')\n"
    }
   ],
   "source": [
    "# Web Solution\n",
    "# Step 1:\n",
    "df=df.rename(columns = {'Type':'CarType'})\n",
    "# or\n",
    "df.columns.values[2] = \"CarType\"\n",
    "\n",
    "# Step 2:\n",
    "df.columns = df.columns.map(lambda x: x.replace('.', '_'))\n",
    "print(df.columns)"
   ]
  },
  {
   "source": [
    "#### 40. How to check if a dataframe has any missing values?\n",
    "Difficulty Level: L1\n",
    "\n",
    "Check if df has any missing values.\n",
    "\n",
    "Input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Manufacturer          True\nModel                 True\nType                  True\nMin.Price             True\nPrice                 True\nMax.Price             True\nMPG.city              True\nMPG.highway           True\nAirBags               True\nDriveTrain            True\nCylinders             True\nEngineSize            True\nHorsepower            True\nRPM                   True\nRev.per.mile          True\nMan.trans.avail       True\nFuel.tank.capacity    True\nPassengers            True\nLength                True\nWheelbase             True\nWidth                 True\nTurn.circle           True\nRear.seat.room        True\nLuggage.room          True\nWeight                True\nOrigin                True\nMake                  True\ndtype: bool"
     },
     "metadata": {},
     "execution_count": 165
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Solution\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "source": [
    "#### 41. How to count the number of missing values in each column?\n",
    "Difficulty Level: L2\n",
    "\n",
    "Count the number of missing values in each column of df. Which column has the maximum number of missing values?\n",
    "\n",
    "Input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Manufacturer           4\nModel                  1\nType                   3\nMin.Price              7\nPrice                  2\nMax.Price              5\nMPG.city               9\nMPG.highway            2\nAirBags                6\nDriveTrain             7\nCylinders              5\nEngineSize             2\nHorsepower             7\nRPM                    3\nRev.per.mile           6\nMan.trans.avail        5\nFuel.tank.capacity     8\nPassengers             2\nLength                 4\nWheelbase              1\nWidth                  6\nTurn.circle            5\nRear.seat.room         4\nLuggage.room          19\nWeight                 7\nOrigin                 5\nMake                   3\ndtype: int64\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('Column has the maximum number of missing values', 'Luggage.room')"
     },
     "metadata": {},
     "execution_count": 177
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "\"Column has the maximum number of missing values\", str(df.isnull().sum().argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'Luggage.room'"
     },
     "metadata": {},
     "execution_count": 168
    }
   ],
   "source": [
    "# Web Solution\n",
    "n_missings_each_col = df.apply(lambda x: x.isnull().sum())\n",
    "n_missings_each_col.argmax()"
   ]
  },
  {
   "source": [
    "#### 42. How to replace missing values of multiple numeric columns with the mean?\n",
    "Difficulty Level: L2\n",
    "\n",
    "Replace missing values in Min.Price and Max.Price columns with their respective mean.\n",
    "\n",
    "Input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0     12.900000\n1     29.200000\n2     25.900000\n3     17.118605\n4     17.118605\n        ...    \n88    16.600000\n89    17.600000\n90    22.900000\n91    21.800000\n92    24.800000\nName: Min.Price, Length: 93, dtype: float64"
     },
     "metadata": {},
     "execution_count": 203
    }
   ],
   "source": [
    "df['Min.Price'] = df['Min.Price'].fillna(np.mean(df['Min.Price']))\n",
    "df['Min.Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0     18.800000\n1     38.700000\n2     32.300000\n3     44.600000\n4     21.459091\n        ...    \n88    22.700000\n89    22.400000\n90    23.700000\n91    23.500000\n92    28.500000\nName: Max.Price, Length: 93, dtype: float64"
     },
     "metadata": {},
     "execution_count": 204
    }
   ],
   "source": [
    "df['Max.Price'] = df['Max.Price'].fillna(np.mean(df['Max.Price']))\n",
    "df['Max.Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "   Min.Price  Max.Price\n0  12.900000  18.800000\n1  29.200000  38.700000\n2  25.900000  32.300000\n3  17.118605  44.600000\n4  17.118605  21.459091\n"
    }
   ],
   "source": [
    "# Solution\n",
    "df_out = df[['Min.Price', 'Max.Price']] = df[['Min.Price', 'Max.Price']].apply(lambda x: x.fillna(x.mean()))\n",
    "print(df_out.head())"
   ]
  },
  {
   "source": [
    "#### 43. How to use apply function on existing columns with global variables as additional arguments?\n",
    "Difficulty Level: L3\n",
    "\n",
    "In df, use apply method to replace the missing values in Min.Price with the column’s mean and those in Max.Price with the column’s median."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  Manufacturer    Model     Type  Min.Price  Price  Max.Price  MPG.city  \\\n0        Acura  Integra    Small       12.9   15.9       18.8      25.0   \n1          NaN   Legend  Midsize       29.2   33.9       38.7      18.0   \n2         Audi       90  Compact       25.9   29.1       32.3      20.0   \n3         Audi      100  Midsize        NaN   37.7       44.6      19.0   \n4          BMW     535i  Midsize        NaN   30.0        NaN      22.0   \n\n   MPG.highway             AirBags DriveTrain  ... Passengers  Length  \\\n0         31.0                None      Front  ...        5.0   177.0   \n1         25.0  Driver & Passenger      Front  ...        5.0   195.0   \n2         26.0         Driver only      Front  ...        5.0   180.0   \n3         26.0  Driver & Passenger        NaN  ...        6.0   193.0   \n4         30.0                 NaN       Rear  ...        4.0   186.0   \n\n   Wheelbase  Width  Turn.circle Rear.seat.room  Luggage.room  Weight  \\\n0      102.0   68.0         37.0           26.5           NaN  2705.0   \n1      115.0   71.0         38.0           30.0          15.0  3560.0   \n2      102.0   67.0         37.0           28.0          14.0  3375.0   \n3      106.0    NaN         37.0           31.0          17.0  3405.0   \n4      109.0   69.0         39.0           27.0          13.0  3640.0   \n\n    Origin           Make  \n0  non-USA  Acura Integra  \n1  non-USA   Acura Legend  \n2  non-USA        Audi 90  \n3  non-USA       Audi 100  \n4  non-USA       BMW 535i  \n\n[5 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Manufacturer</th>\n      <th>Model</th>\n      <th>Type</th>\n      <th>Min.Price</th>\n      <th>Price</th>\n      <th>Max.Price</th>\n      <th>MPG.city</th>\n      <th>MPG.highway</th>\n      <th>AirBags</th>\n      <th>DriveTrain</th>\n      <th>...</th>\n      <th>Passengers</th>\n      <th>Length</th>\n      <th>Wheelbase</th>\n      <th>Width</th>\n      <th>Turn.circle</th>\n      <th>Rear.seat.room</th>\n      <th>Luggage.room</th>\n      <th>Weight</th>\n      <th>Origin</th>\n      <th>Make</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>Acura</td>\n      <td>Integra</td>\n      <td>Small</td>\n      <td>12.9</td>\n      <td>15.9</td>\n      <td>18.8</td>\n      <td>25.0</td>\n      <td>31.0</td>\n      <td>None</td>\n      <td>Front</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>177.0</td>\n      <td>102.0</td>\n      <td>68.0</td>\n      <td>37.0</td>\n      <td>26.5</td>\n      <td>NaN</td>\n      <td>2705.0</td>\n      <td>non-USA</td>\n      <td>Acura Integra</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>NaN</td>\n      <td>Legend</td>\n      <td>Midsize</td>\n      <td>29.2</td>\n      <td>33.9</td>\n      <td>38.7</td>\n      <td>18.0</td>\n      <td>25.0</td>\n      <td>Driver &amp; Passenger</td>\n      <td>Front</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>195.0</td>\n      <td>115.0</td>\n      <td>71.0</td>\n      <td>38.0</td>\n      <td>30.0</td>\n      <td>15.0</td>\n      <td>3560.0</td>\n      <td>non-USA</td>\n      <td>Acura Legend</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>Audi</td>\n      <td>90</td>\n      <td>Compact</td>\n      <td>25.9</td>\n      <td>29.1</td>\n      <td>32.3</td>\n      <td>20.0</td>\n      <td>26.0</td>\n      <td>Driver only</td>\n      <td>Front</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>180.0</td>\n      <td>102.0</td>\n      <td>67.0</td>\n      <td>37.0</td>\n      <td>28.0</td>\n      <td>14.0</td>\n      <td>3375.0</td>\n      <td>non-USA</td>\n      <td>Audi 90</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>Audi</td>\n      <td>100</td>\n      <td>Midsize</td>\n      <td>NaN</td>\n      <td>37.7</td>\n      <td>44.6</td>\n      <td>19.0</td>\n      <td>26.0</td>\n      <td>Driver &amp; Passenger</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>6.0</td>\n      <td>193.0</td>\n      <td>106.0</td>\n      <td>NaN</td>\n      <td>37.0</td>\n      <td>31.0</td>\n      <td>17.0</td>\n      <td>3405.0</td>\n      <td>non-USA</td>\n      <td>Audi 100</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>BMW</td>\n      <td>535i</td>\n      <td>Midsize</td>\n      <td>NaN</td>\n      <td>30.0</td>\n      <td>NaN</td>\n      <td>22.0</td>\n      <td>30.0</td>\n      <td>NaN</td>\n      <td>Rear</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>186.0</td>\n      <td>109.0</td>\n      <td>69.0</td>\n      <td>39.0</td>\n      <td>27.0</td>\n      <td>13.0</td>\n      <td>3640.0</td>\n      <td>non-USA</td>\n      <td>BMW 535i</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 208
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}