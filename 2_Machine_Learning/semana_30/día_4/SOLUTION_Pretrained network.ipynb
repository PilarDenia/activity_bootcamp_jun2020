{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre trained network\n",
    "![imagen](https://www.researchgate.net/publication/336874848/figure/fig1/AS:819325225144320@1572353764073/Illustrations-of-transfer-learning-a-neural-network-is-pretrained-on-ImageNet-and.png)\n",
    "\n",
    "Estas son las arquitecturas de redes neuronales más utilizadas en la comunidad. Para más detalle sobre el funcionamiento de cada red, consultar el *Hands on Machine Learning for Python*.\n",
    "* VGG-16\n",
    "* VGG-19\n",
    "* Inception V3\n",
    "* XCeption\n",
    "* ResNet-50\n",
    "\n",
    "Estas redes las podemos incorporar entrenadas, o sin entrenar.\n",
    "\n",
    "## ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, decode_predictions, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "imagenet es un corpus de imagenes con el que se ha clasificado el ResNet50V2\n",
    "http://www.image-net.org/\n",
    "\n",
    "Cargamos toda la red ya entrenada, y la usaremos para predecir\n",
    "include_top=True --> Para que incluya la fully connected layer.\n",
    "include_top=False --> Desarrollamos la fully connected layer\n",
    "ojo el input shape que sea el de las imagenes que introduciremos. Esta limitado a imagenes de tamaño n\n",
    "classifier_activation se usa si include_top=True\n",
    "'''\n",
    "\n",
    "base_model = ResNet50V2(input_shape=(224, 224,3),\n",
    "                        include_top=True,\n",
    "                        weights=\"imagenet\",\n",
    "                        classifier_activation=\"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50v2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, 56, 56, 64)   256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, 56, 56, 64)   0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, 56, 56, 256)  0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 28, 28, 64)   36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 28, 28, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 28, 28, 256)  0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 28, 28, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, 28, 28, 256)  0           max_pooling2d[0][0]              \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, 28, 28, 256)  1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, 28, 28, 256)  0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, 28, 28, 512)  0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 14, 14, 128)  147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 14, 14, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 512)  0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 14, 14, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, 14, 14, 512)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, 14, 14, 512)  2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, 14, 14, 512)  0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, 7, 7, 1024)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, 7, 7, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_conv[0][0]        \n",
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, 7, 7, 2048)   8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, 7, 7, 2048)   0           post_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           post_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,613,800\n",
      "Trainable params: 25,568,360\n",
      "Non-trainable params: 45,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos algunas imagenes desde local, para ver qué tal funciona la red ResNet50V2 ya entrenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img/bear-1.jpg\n",
      "img/cat.8016.jpg\n",
      "img/cat.8037.jpg\n",
      "img/dog.11856.jpg\n",
      "img/dog.11857.jpg\n",
      "img/horse.jpg\n",
      "img/karate.jpg\n",
      "img/pizza.jpg\n",
      "(8, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def read_data(path):\n",
    "    X = []\n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        image = imread(path + '/' + file)\n",
    "        smallimage = cv2.resize(image, (224, 224))\n",
    "        print(path + '/' + file)\n",
    "        \n",
    "        X.append(smallimage)\n",
    "\n",
    "    return np.array(X)\n",
    "    \n",
    "\n",
    "x_test = read_data('img')\n",
    "\n",
    "# Procesar las imagenes tal y como entran en el modelo\n",
    "x_test = preprocess_input(x_test)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Predicted:\n",
      " brown_bear 0.999445\n",
      "Predicted:\n",
      " chow 0.00054156024\n",
      "Predicted:\n",
      " American_black_bear 8.781006e-06\n",
      "Predicted:\n",
      " ice_bear 1.1076199e-06\n",
      "Predicted:\n",
      " howler_monkey 4.4061818e-07\n",
      "####################\n",
      "Predicted:\n",
      " Egyptian_cat 0.64985013\n",
      "Predicted:\n",
      " Siamese_cat 0.16787368\n",
      "Predicted:\n",
      " tiger_cat 0.060449515\n",
      "Predicted:\n",
      " lynx 0.024389781\n",
      "Predicted:\n",
      " tabby 0.017880365\n",
      "####################\n",
      "Predicted:\n",
      " Egyptian_cat 0.8209842\n",
      "Predicted:\n",
      " lynx 0.12679438\n",
      "Predicted:\n",
      " Siamese_cat 0.021530626\n",
      "Predicted:\n",
      " tabby 0.020569604\n",
      "Predicted:\n",
      " tiger_cat 0.007405382\n",
      "####################\n",
      "Predicted:\n",
      " Rottweiler 0.732909\n",
      "Predicted:\n",
      " Brabancon_griffon 0.085085\n",
      "Predicted:\n",
      " Staffordshire_bullterrier 0.031059418\n",
      "Predicted:\n",
      " EntleBucher 0.023099238\n",
      "Predicted:\n",
      " Doberman 0.019871488\n",
      "####################\n",
      "Predicted:\n",
      " collie 0.99525696\n",
      "Predicted:\n",
      " Shetland_sheepdog 0.0047429753\n",
      "Predicted:\n",
      " yellow_lady's_slipper 9.142575e-09\n",
      "Predicted:\n",
      " goldfinch 8.13325e-09\n",
      "Predicted:\n",
      " groenendael 7.536617e-09\n",
      "####################\n",
      "Predicted:\n",
      " standard_poodle 0.32455865\n",
      "Predicted:\n",
      " Saluki 0.30035383\n",
      "Predicted:\n",
      " ram 0.12327859\n",
      "Predicted:\n",
      " bighorn 0.11541238\n",
      "Predicted:\n",
      " Ibizan_hound 0.059749037\n",
      "####################\n",
      "Predicted:\n",
      " ballplayer 0.54023343\n",
      "Predicted:\n",
      " baseball 0.24657947\n",
      "Predicted:\n",
      " balance_beam 0.11725281\n",
      "Predicted:\n",
      " torch 0.018078027\n",
      "Predicted:\n",
      " puck 0.009959704\n",
      "####################\n",
      "Predicted:\n",
      " pizza 0.9971306\n",
      "Predicted:\n",
      " bagel 0.0011670357\n",
      "Predicted:\n",
      " potpie 0.0010403863\n",
      "Predicted:\n",
      " carbonara 0.00010587162\n",
      "Predicted:\n",
      " French_loaf 9.187512e-05\n"
     ]
    }
   ],
   "source": [
    "preds = base_model.predict(x_test)\n",
    "\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "decodes = decode_predictions(preds, top=5)\n",
    "\n",
    "for j in decodes:\n",
    "    print('####################')\n",
    "    for i,decode in enumerate(j):\n",
    "        print('Predicted:\\n', decode[1], decode[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16\n",
    "En este caso vamos a importar la red VGG16, que utilizaremos como red preentrenada y completaremos con una fully connected layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "IM_SIZE=64\n",
    "\n",
    "TRAIN_PATH = 'C:/Users/Alberto.Romero/Pictures/The Bridge DS/Redes Neuronales2/cats_dogs_img/train'\n",
    "#TRAIN_PATH = 'C:/Users/Daney/Desktop/dogs&cats/mini_train/train/'\n",
    "filenames = os.listdir(TRAIN_PATH)\n",
    "categories = []\n",
    "for filename in filenames:\n",
    "    category = filename.split('.')[0]\n",
    "    categories.append(category)\n",
    "    \n",
    "df = pd.DataFrame({\n",
    "    'filenames': filenames,\n",
    "    'category': categories\n",
    "})\n",
    "\n",
    "train_df, validate_df = train_test_split(df,\n",
    "                                         test_size=0.20,\n",
    "                                         random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "validation_datagen = ImageDataGenerator(rescale = 1.0/255. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                    TRAIN_PATH,\n",
    "                                                    x_col='filenames',\n",
    "                                                    y_col='category',\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary',\n",
    "                                                    target_size = (IM_SIZE, IM_SIZE))\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_dataframe(validate_df,\n",
    "                                                              TRAIN_PATH,\n",
    "                                                              x_col='filenames',\n",
    "                                                              y_col='category',\n",
    "                                                              batch_size = 20,\n",
    "                                                              class_mode = 'binary',\n",
    "                                                              target_size = (IM_SIZE, IM_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nNote that we have 2 ways of writing the same code:\\n\\nmodel = VGG19(weights='imagenet',include_top=False)\\nmodel.trainable=False\\nlayer1 = Flatten(name='flat')(model)\\nlayer2 = Dense(512, activation='relu', name='fc1')(layer1)\\nlayer3 = Dense(512, activation='relu', name='fc2')(layer2)\\nlayer4 = Dense(10, activation='softmax', name='predictions')(layer3)\\n\\nwhich could be rewritten as:\\n\\nmodel = VGG19(weights='imagenet',include_top=False)\\nmodel.trainable=False\\nmodel.add( Flatten(name='flat'))\\nmodel.add( Dense(512, activation='relu', name='fc1'))\\nmodel.add( Dense(512, activation='relu', name='fc2'))\\nmodel.add( Dense(10, activation='softmax', name='predictions'))\\n\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Note that we have 2 ways of writing the same code:\n",
    "\n",
    "model = VGG19(weights='imagenet',include_top=False)\n",
    "model.trainable=False\n",
    "layer1 = Flatten(name='flat')(model)\n",
    "layer2 = Dense(512, activation='relu', name='fc1')(layer1)\n",
    "layer3 = Dense(512, activation='relu', name='fc2')(layer2)\n",
    "layer4 = Dense(10, activation='softmax', name='predictions')(layer3)\n",
    "\n",
    "which could be rewritten as:\n",
    "\n",
    "model = VGG19(weights='imagenet',include_top=False)\n",
    "model.trainable=False\n",
    "model.add( Flatten(name='flat'))\n",
    "model.add( Dense(512, activation='relu', name='fc1'))\n",
    "model.add( Dense(512, activation='relu', name='fc2'))\n",
    "model.add( Dense(10, activation='softmax', name='predictions'))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "base_model = VGG16(input_shape = (IM_SIZE, IM_SIZE, 3), # Shape of our images\n",
    "                    include_top = False, # Leave out the last fully connected layer\n",
    "                    weights = 'imagenet')\n",
    "\n",
    "# No queremos que entrenen en el fit\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "##### FULLY CONNECTED LAYER #####\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Steps per epoch denote the number of batches to be selected for one epoch\n",
    "#\n",
    "# A training step is one gradient update. In one step batch_size many examples are processed.\n",
    "# An epoch consists of one full cycle through the training data. This is usually many steps.\n",
    "#\n",
    "# As an example, if you have 2000 images and use a batch_size of 10, an epoch consists of\n",
    "# 2000 images / (10 images/step) = 200 steps\n",
    "#\n",
    "# If you choose your training image randomly and independent in each step, you normally do not call it \"epoch\"\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "batch_size determines the number of samples in each mini batch.\n",
    "Its maximum is the number of all samples, which makes gradient descent accurate,\n",
    "the loss will decrease towards the minimum if the learning rate is small enough,\n",
    "but iterations are slower.\n",
    "Its minimum is 1, resulting in stochastic gradient descent: Fast but the direction of the gradient step is based only on one example,\n",
    "the loss may jump around.\n",
    "\n",
    "batch_size allows to adjust between the two extremes: accurate gradient direction and fast iteration.\n",
    "Also, the maximum value for batch_size may be limited if your model + data set does not fit into the available (GPU) memory.\n",
    "\n",
    "steps_per_epoch the number of batch iterations before a training epoch is considered finished.\n",
    "If you have a training set of fixed size you can ignore it but it may be useful if you have a huge data set\n",
    "or if you are generating random data augmentations on the fly, i.e.\n",
    "if your training set has a (generated) infinite size.\n",
    "If you have the time to go through your whole training data set I recommend to skip this parameter.\n",
    "\n",
    "validation_steps similar to steps_per_epoch but on the validation data set instead on the training data.\n",
    "If you have the time to go through your whole validation data set I recommend to skip this parameter.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 139s 1s/step - loss: 0.7629 - acc: 0.6017 - val_loss: 0.5269 - val_acc: 0.7388\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 137s 1s/step - loss: 0.5782 - acc: 0.7133 - val_loss: 0.5143 - val_acc: 0.7420\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 137s 1s/step - loss: 0.5883 - acc: 0.6717 - val_loss: 0.4743 - val_acc: 0.7718\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 136s 1s/step - loss: 0.5738 - acc: 0.6962 - val_loss: 0.4761 - val_acc: 0.7650\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 135s 1s/step - loss: 0.5373 - acc: 0.7075 - val_loss: 0.4865 - val_acc: 0.7592\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 147s 1s/step - loss: 0.5130 - acc: 0.7422 - val_loss: 0.4749 - val_acc: 0.7684\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 135s 1s/step - loss: 0.5598 - acc: 0.7126 - val_loss: 0.4625 - val_acc: 0.7848\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 132s 1s/step - loss: 0.5226 - acc: 0.7229 - val_loss: 0.4544 - val_acc: 0.7868\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 132s 1s/step - loss: 0.5110 - acc: 0.7487 - val_loss: 0.4692 - val_acc: 0.7732\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 133s 1s/step - loss: 0.5309 - acc: 0.7163 - val_loss: 0.4937 - val_acc: 0.7466\n"
     ]
    }
   ],
   "source": [
    "vgghist = model.fit(train_generator,\n",
    "                    validation_data = validation_generator,\n",
    "                    steps_per_epoch = 100,\n",
    "                    epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "IM_SIZE=150\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                    TRAIN_PATH,\n",
    "                                                    x_col='filenames',\n",
    "                                                    y_col='category',\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary',\n",
    "                                                    target_size = (IM_SIZE, IM_SIZE))\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_dataframe(validate_df,\n",
    "                                                              TRAIN_PATH,\n",
    "                                                              x_col='filenames',\n",
    "                                                              y_col='category',\n",
    "                                                              batch_size = 20,\n",
    "                                                              class_mode = 'binary',\n",
    "                                                              target_size = (IM_SIZE, IM_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "base_model = InceptionV3(input_shape = (IM_SIZE, IM_SIZE, 3),\n",
    "                         include_top = False,\n",
    "                         weights = 'imagenet')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 162s 2s/step - loss: 2.6778 - acc: 0.7852 - val_loss: 0.1799 - val_acc: 0.9434\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 155s 2s/step - loss: 0.4198 - acc: 0.8826 - val_loss: 0.1419 - val_acc: 0.9572\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 155s 2s/step - loss: 0.4073 - acc: 0.8810 - val_loss: 0.2837 - val_acc: 0.9274\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 156s 2s/step - loss: 0.3501 - acc: 0.9014 - val_loss: 0.1349 - val_acc: 0.9556\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 169s 2s/step - loss: 0.2749 - acc: 0.9207 - val_loss: 0.2399 - val_acc: 0.9414\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 165s 2s/step - loss: 0.3459 - acc: 0.9018 - val_loss: 0.2332 - val_acc: 0.9366\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 160s 2s/step - loss: 0.2839 - acc: 0.9083 - val_loss: 0.1625 - val_acc: 0.9596\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 166s 2s/step - loss: 0.2973 - acc: 0.9113 - val_loss: 0.1740 - val_acc: 0.9578\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 160s 2s/step - loss: 0.3143 - acc: 0.9131 - val_loss: 0.1453 - val_acc: 0.9594\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 160s 2s/step - loss: 0.2481 - acc: 0.9341 - val_loss: 0.1974 - val_acc: 0.9508\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "x = layers.Flatten()(base_model.output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), loss = 'binary_crossentropy', metrics = ['acc'])\n",
    "\n",
    "inc_history = model.fit(train_generator,\n",
    "                      validation_data = validation_generator,\n",
    "                      steps_per_epoch = 100,\n",
    "                      epochs = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50V2 sin entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_SIZE=32\n",
    "\n",
    "base_model = ResNet50V2(input_shape=(IM_SIZE, IM_SIZE,3),\n",
    "                        include_top=False,\n",
    "                        classifier_activation=\"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                    TRAIN_PATH,\n",
    "                                                    x_col='filenames',\n",
    "                                                    y_col='category',\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary',\n",
    "                                                    target_size = (IM_SIZE, IM_SIZE))\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_dataframe(validate_df,\n",
    "                                                              TRAIN_PATH,\n",
    "                                                              x_col='filenames',\n",
    "                                                              y_col='category',\n",
    "                                                              batch_size = 20,\n",
    "                                                              class_mode = 'binary',\n",
    "                                                              target_size = (IM_SIZE, IM_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 124s 1s/step - loss: 0.7932 - acc: 0.5034 - val_loss: 0.6935 - val_acc: 0.5432\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 119s 1s/step - loss: 0.7338 - acc: 0.5313 - val_loss: 0.6785 - val_acc: 0.5760\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 120s 1s/step - loss: 0.7045 - acc: 0.5481 - val_loss: 0.6682 - val_acc: 0.6070\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 119s 1s/step - loss: 0.7034 - acc: 0.5628 - val_loss: 1.1696 - val_acc: 0.5868\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 123s 1s/step - loss: 0.6928 - acc: 0.5655 - val_loss: 0.7042 - val_acc: 0.6100\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 120s 1s/step - loss: 0.7028 - acc: 0.5721 - val_loss: 1.2627 - val_acc: 0.6256\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 118s 1s/step - loss: 0.6733 - acc: 0.5898 - val_loss: 0.8063 - val_acc: 0.6460\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 118s 1s/step - loss: 0.6720 - acc: 0.6184 - val_loss: 0.6324 - val_acc: 0.6750\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 117s 1s/step - loss: 0.6622 - acc: 0.6313 - val_loss: 0.7656 - val_acc: 0.6710\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 119s 1s/step - loss: 0.6821 - acc: 0.6261 - val_loss: 0.6946 - val_acc: 0.6488\n"
     ]
    }
   ],
   "source": [
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), loss = 'binary_crossentropy',metrics = ['acc'])\n",
    "\n",
    "history = model.fit(train_generator, validation_data = validation_generator, steps_per_epoch = 100, epochs = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 116s 1s/step - loss: 0.6531 - acc: 0.6770 - val_loss: 0.6559 - val_acc: 0.6906\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 117s 1s/step - loss: 0.6704 - acc: 0.6340 - val_loss: 0.7215 - val_acc: 0.6748\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 117s 1s/step - loss: 0.6620 - acc: 0.6315 - val_loss: 0.5994 - val_acc: 0.7116\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 117s 1s/step - loss: 0.6398 - acc: 0.6770 - val_loss: 0.8550 - val_acc: 0.7064\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 121s 1s/step - loss: 0.6283 - acc: 0.6795 - val_loss: 1.5717 - val_acc: 0.6562\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 124s 1s/step - loss: 0.6390 - acc: 0.6635 - val_loss: 1.0811 - val_acc: 0.7168\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 120s 1s/step - loss: 0.6410 - acc: 0.6745 - val_loss: 1.3255 - val_acc: 0.6736\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 119s 1s/step - loss: 0.5911 - acc: 0.7005 - val_loss: 0.7157 - val_acc: 0.7356\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 122s 1s/step - loss: 0.6396 - acc: 0.6680 - val_loss: 1.8871 - val_acc: 0.6160\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 120s 1s/step - loss: 0.6142 - acc: 0.6850 - val_loss: 1.5186 - val_acc: 0.6664\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, validation_data = validation_generator, steps_per_epoch = 100, epochs = 10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
