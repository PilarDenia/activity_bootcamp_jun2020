{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre trained network\n",
    "![imagen](https://www.researchgate.net/publication/336874848/figure/fig1/AS:819325225144320@1572353764073/Illustrations-of-transfer-learning-a-neural-network-is-pretrained-on-ImageNet-and.png)\n",
    "\n",
    "Estas son las arquitecturas de redes neuronales más utilizadas en la comunidad. Para más detalle sobre el funcionamiento de cada red, consultar el *Hands on Machine Learning for Python*.\n",
    "* VGG-16\n",
    "* VGG-19\n",
    "* Inception V3\n",
    "* XCeption\n",
    "* ResNet-50\n",
    "\n",
    "Estas redes las podemos incorporar entrenadas, o sin entrenar.\n",
    "\n",
    "## ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, decode_predictions, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102875136/102869336 [==============================] - 492s 5us/step\n"
     ]
    }
   ],
   "source": [
    "#### CODE ####\n",
    "base_model = ResNet50V2(input_shape=(224,224,3),  #La red ResNet50V2, está abierta pero 'sólo' acepta entrada de 224 * 224 pixeles\n",
    "                        include_top=True, #Incluye todo, no solo la parte de Convoluciones si no con sus propias ce NN(redNeuronal) también.\n",
    "                        weights= 'imagenet', #La red de imgenes con sus categorias\n",
    "                        classifier_activation= 'softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "elu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, 7, 7, 1024)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, 7, 7, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_conv[0][0]        \n",
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, 7, 7, 2048)   8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, 7, 7, 2048)   0           post_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           post_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,613,800\n",
      "Trainable params: 25,568,360\n",
      "Non-trainable params: 45,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#### CODE ####\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos algunas imagenes desde local, para ver qué tal funciona la red ResNet50V2 ya entrenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "img/bear-1.jpg\nimg/cat.8016.jpg\nimg/cat.8037.jpg\nimg/dog.11856.jpg\nimg/dog.11857.jpg\nimg/horse.jpg\nimg/karate.jpg\nimg/pizza.jpg\n(8, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def read_data(path):\n",
    "    X = []\n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        image = imread(path + '/' + file)\n",
    "        smallimage = cv2.resize(image, (224, 224))\n",
    "        print(path + '/' + file)\n",
    "        \n",
    "        X.append(smallimage)\n",
    "\n",
    "    return np.array(X)\n",
    "    \n",
    "\n",
    "x_test = read_data('img')\n",
    "\n",
    "# Procesar las imagenes tal y como entran en el modelo\n",
    "x_test = preprocess_input(x_test)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "40960/35363 [==================================] - 1s 16us/step\n",
      "#########\n",
      "Predicted:\n",
      " brown_bear 0.99944514\n",
      "Predicted:\n",
      " chow 0.00054139504\n",
      "Predicted:\n",
      " American_black_bear 8.784533e-06\n",
      "Predicted:\n",
      " ice_bear 1.1080934e-06\n",
      "Predicted:\n",
      " howler_monkey 4.4057498e-07\n",
      "#########\n",
      "Predicted:\n",
      " Egyptian_cat 0.659723\n",
      "Predicted:\n",
      " Siamese_cat 0.15741089\n",
      "Predicted:\n",
      " tiger_cat 0.06260011\n",
      "Predicted:\n",
      " lynx 0.022836583\n",
      "Predicted:\n",
      " tabby 0.018356169\n",
      "#########\n",
      "Predicted:\n",
      " Egyptian_cat 0.8211865\n",
      "Predicted:\n",
      " lynx 0.12932149\n",
      "Predicted:\n",
      " Siamese_cat 0.021827206\n",
      "Predicted:\n",
      " tabby 0.018324552\n",
      "Predicted:\n",
      " tiger_cat 0.006797261\n",
      "#########\n",
      "Predicted:\n",
      " Rottweiler 0.76189536\n",
      "Predicted:\n",
      " Brabancon_griffon 0.0746136\n",
      "Predicted:\n",
      " Staffordshire_bullterrier 0.028572641\n",
      "Predicted:\n",
      " EntleBucher 0.019904258\n",
      "Predicted:\n",
      " Doberman 0.019285118\n",
      "#########\n",
      "Predicted:\n",
      " collie 0.99525565\n",
      "Predicted:\n",
      " Shetland_sheepdog 0.004744308\n",
      "Predicted:\n",
      " yellow_lady's_slipper 9.751216e-09\n",
      "Predicted:\n",
      " goldfinch 8.175372e-09\n",
      "Predicted:\n",
      " groenendael 7.475547e-09\n",
      "#########\n",
      "Predicted:\n",
      " standard_poodle 0.32618603\n",
      "Predicted:\n",
      " Saluki 0.29635718\n",
      "Predicted:\n",
      " ram 0.12240928\n",
      "Predicted:\n",
      " bighorn 0.11814768\n",
      "Predicted:\n",
      " Ibizan_hound 0.060498703\n",
      "#########\n",
      "Predicted:\n",
      " ballplayer 0.54023343\n",
      "Predicted:\n",
      " baseball 0.24657947\n",
      "Predicted:\n",
      " balance_beam 0.11725281\n",
      "Predicted:\n",
      " torch 0.018078027\n",
      "Predicted:\n",
      " puck 0.009959704\n",
      "#########\n",
      "Predicted:\n",
      " pizza 0.9974214\n",
      "Predicted:\n",
      " bagel 0.0011646893\n",
      "Predicted:\n",
      " potpie 0.00081819936\n",
      "Predicted:\n",
      " carbonara 9.463562e-05\n",
      "Predicted:\n",
      " French_loaf 8.5962834e-05\n"
     ]
    }
   ],
   "source": [
    "#### CODE ####\n",
    "preds = base_model.predict(x_test)\n",
    "\n",
    "#decode the results into a list of tuples (class, description, probability)\n",
    "decodes = decode_predictions(preds, top= 5)\n",
    "\n",
    "for j in decodes:\n",
    "    print(\"#########\")\n",
    "    for i, decode in enumerate(j):\n",
    "        print(\"Predicted:\\n\", decode[1], decode[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16\n",
    "En este caso vamos a importar la red VGG16, que utilizaremos como red preentrenada y completaremos con una fully connected layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= \"../../../../DataSets/dogs_cats/\"\n",
    "folder_train = \"train/\"\n",
    "folder_test = \"test1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "IM_SIZE=64\n",
    "\n",
    "TRAIN_PATH = path + folder_train\n",
    "\n",
    "filenames = os.listdir(TRAIN_PATH)\n",
    "categories = []\n",
    "for filename in filenames:\n",
    "    category = filename.split('.')[0]\n",
    "    categories.append(category)\n",
    "    \n",
    "df = pd.DataFrame({\n",
    "    'filenames': filenames,\n",
    "    'category': categories\n",
    "})\n",
    "\n",
    "train_df, validate_df = train_test_split(df,\n",
    "                                         test_size=0.20,\n",
    "                                         random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['dog.9990.jpg',\n",
       " 'dog.9991.jpg',\n",
       " 'dog.9992.jpg',\n",
       " 'dog.9993.jpg',\n",
       " 'dog.9994.jpg',\n",
       " 'dog.9995.jpg',\n",
       " 'dog.9996.jpg',\n",
       " 'dog.9997.jpg',\n",
       " 'dog.9998.jpg',\n",
       " 'dog.9999.jpg']"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "os.listdir(TRAIN_PATH)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "validation_datagen = ImageDataGenerator(rescale = 1.0/255. ) #Sólo escala los registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                    TRAIN_PATH,\n",
    "                                                    x_col='filenames',\n",
    "                                                    y_col='category',\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary',\n",
    "                                                    target_size = (IM_SIZE, IM_SIZE))\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_dataframe(validate_df,\n",
    "                                                              TRAIN_PATH,\n",
    "                                                              x_col='filenames',\n",
    "                                                              y_col='category',\n",
    "                                                              batch_size = 20,\n",
    "                                                              class_mode = 'binary',\n",
    "                                                              target_size = (IM_SIZE, IM_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CODE ####\n",
    "from tensorflow.keras.applications.vgg16 import VGG16 \n",
    "\n",
    "base_model = VGG16(input_shape=(IM_SIZE, IM_SIZE, 3),\n",
    "                   include_top= False, #No me la conectes a la última red_nn (NN==> NeuronalNet)\n",
    "                   weights= 'imagenet') #los pesos los saque de una base de datos 'image_net' de imagenes_clasificadas\n",
    "\n",
    "#No queremos que entrene en el fit\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "##### FULLY CONNECTED LAYER #####\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 554s 553ms/step - loss: 0.6092 - acc: 0.6843 - val_loss: 0.4660 - val_acc: 0.7738\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 554s 554ms/step - loss: 0.5249 - acc: 0.7332 - val_loss: 0.4574 - val_acc: 0.7826\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 550s 550ms/step - loss: 0.5020 - acc: 0.7536 - val_loss: 0.4500 - val_acc: 0.7810\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 516s 516ms/step - loss: 0.4962 - acc: 0.7551 - val_loss: 0.4392 - val_acc: 0.7906\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 532s 532ms/step - loss: 0.4836 - acc: 0.7632 - val_loss: 0.4356 - val_acc: 0.7894\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 530s 529ms/step - loss: 0.4885 - acc: 0.7550 - val_loss: 0.4273 - val_acc: 0.7984\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 0.4863 - acc: 0.7593 - val_loss: 0.4377 - val_acc: 0.7890\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 0.4967 - acc: 0.7542 - val_loss: 0.4686 - val_acc: 0.7696\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 532s 531ms/step - loss: 0.4860 - acc: 0.7564 - val_loss: 0.4271 - val_acc: 0.7914\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 0.4709 - acc: 0.7685 - val_loss: 0.4129 - val_acc: 0.8074\n"
     ]
    }
   ],
   "source": [
    "vgghist = model.fit(train_generator,\n",
    "                    validation_data = validation_generator,\n",
    "                    epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Otra plantilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_SIZE = 150\n",
    "\n",
    "#flow training images in batches of 20 using train datagen generator\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                      TRAIN_PATH,\n",
    "                                                      x_col = 'filename',\n",
    "                                                      y_col = 'category',\n",
    "                                                      batch_size = 20,\n",
    "                                                      class_mode = 'binary',\n",
    "                                                      target_size = (IM_SIZE, IM_SIZE))\n",
    "\n",
    "#flow validation images in batches of 20 using test datagen generator\n",
    "validation_generator = validation_datagen.flow_from_dataframe(validate_df,\n",
    "                                                              TRAIN_PATH,\n",
    "                                                              x_col = 'filename',\n",
    "                                                              y_col = 'category',\n",
    "                                                              batch_size = 20,\n",
    "                                                              class_mode = 'binary',\n",
    "                                                              target_size = (IM_SIZE, IM_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "base_model = InceptionV3(input_shape = (IM_SIZE, IM_SIZE, 3),\n",
    "                                        include_top = False,\n",
    "                                        weights = 'imagenet')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "x = layers.Flatten()(base_model.output)\n",
    "\n",
    "x = layers.Dense(units= 1024, activation = 'relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "x = layers.Dense(units= 1, activation = 'sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = RMSprop(lr = 0.0001),\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics =  ['acc'])\n",
    "\n",
    "inc_history = model.fit(train_generator,\n",
    "                        validation_data = validation_generator,\n",
    "                        steps_per_epoch = 100,\n",
    "                        epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sintaxis ### \n",
    "\n",
    "\"\"\"\n",
    "Note that there are 2 ways of writing the same code:\n",
    "\n",
    "model = VGG19(weigths= 'imagenet', include_top = False)\n",
    "model.trainable = False\n",
    "\n",
    "layer1 = Flatten(name= 'flat') (model)\n",
    "layer2 = Dense(units= 512, activation = 'relu', name = 'fc1')(layer1)\n",
    "layer3 = Dense(units= 512, activation = 'relu', name = 'fc2')(layer2)\n",
    "layer4 = Dense(units= 10, activation = 'softmax', name = 'predictions')(layer3)\n",
    "\n",
    "#That can be rewritten as:\n",
    "\n",
    "model = VGG19(weigths= 'imagenet', include_top = False)\n",
    "model.trainable = False\n",
    "\n",
    "model.add(Flatten(name= 'flat))\n",
    "model.add(Dense(units= 512, activation = 'relu', name = 'fc1'))\n",
    "model.add(Dense(units= 512, activation = 'relu', name = 'fc2'))\n",
    "model.add(Dense(units= 10, activation = 'softmax', name = 'predictions'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50V2 sin entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_SIZE = 32\n",
    "\n",
    "base_model = ResNet50V2(input_shape= (IM_SIZE, IM_SIZE, 3),\n",
    "                        include_top = False,\n",
    "                        classifier_activation = 'softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'IM' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-1ea51b2cbde0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m                                                               \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                                                               \u001b[0mclass_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'binary'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                                                               target_size = (IM))\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'IM' is not defined"
     ]
    }
   ],
   "source": [
    "#Flow training images in batches of 20 using train_datagen generator\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                    TRAIN_PATH,\n",
    "                                                    x_col = 'filenames',\n",
    "                                                    y_col = 'category',\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary',\n",
    "                                                    target_size = (IM_SIZE, IM_SIZE))\n",
    "\n",
    "\n",
    "#Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_dataframe(validate_df,\n",
    "                                                              TRAIN_PATH,\n",
    "                                                              x_col = 'filename',\n",
    "                                                              y_col = 'category',\n",
    "                                                              batch_size = 20,\n",
    "                                                              class_mode = 'binary',\n",
    "                                                              target_size = (IM_SIZE, IM_SIZE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten(base_model.output)\n",
    "\n",
    "#add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "#add a final dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "model.compile(optimizer = tf.keras.optimizers.RMSprop(lr = 0.0001),\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['acc'])\n",
    "\n",
    "history = model.fit(train_generator, \n",
    "                    validation_data = validation_generator,\n",
    "                    steps_per_epoch = 100,\n",
    "                    epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, \n",
    "                    validation_data = validation_generator,\n",
    "                    steps_per_epoch = 100,\n",
    "                    epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejecutar el entrenamiento 2 veces es igual a haberlo entrenado una sola vez pero 20Epochs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}