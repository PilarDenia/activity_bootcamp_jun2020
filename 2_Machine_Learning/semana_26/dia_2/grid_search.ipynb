{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch & Pipelines\n",
    "GridSearch is an optimization tool that we use when tuning hyperparameters. We define the grid of parameters that we want to search through, and we select the best combination of parameters for our data."
   ]
  },
  {
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - One way\n",
    "Itera un algoritmo sobre un conjunto de hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer #para introducirlo como parte del proceso en Pipeline, y computa/Nan en el modelo...pero OJO!! todo el dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest # Mediante test estadistico, busca la mejores features, por correlaciones... y seleec... parecido a 'features_importance_' de Modelos de 'DecisionTreeClassifier'\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 192 candidates, totalling 1920 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 428 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1920 out of 1920 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.01, 0.01, 0.5, 1, 5, 10, 100],\n",
       "                         'coef0': [-1, 0, 1], 'gamma': ['scale', 'auto'],\n",
       "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=True)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action=\"ignore\",category=DeprecationWarning)\n",
    "warnings.filterwarnings(action=\"ignore\",category=FutureWarning)\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                   y,\n",
    "                                                   test_size = 0.2,\n",
    "                                                   random_state=42)\n",
    "\n",
    "####### GridSearchCV#######\n",
    "#Modelo\n",
    "svc = SVC()\n",
    "\n",
    "#definir los parametros para GridSearchCV\n",
    "parameters ={'kernel': ['linear','poly','rbf','sigmoid'],\n",
    "             'C': [0.001, 0.01, 0.01, 0.5, 1, 5, 10, 100],\n",
    "             'gamma': ['scale','auto'],\n",
    "             'coef0':[-1, 0, 1]}\n",
    "\n",
    "grid = GridSearchCV(estimator= svc,\n",
    "                    param_grid=parameters,\n",
    "                    n_jobs=-1, #Usa todos los cores que puedas, como capacidad de computación\n",
    "                    scoring='accuracy',\n",
    "                    verbose=True,\n",
    "                    cv=10)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best estimator: SVC(C=0.5, cache_size=200, class_weight=None, coef0=-1,\n    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n    max_iter=-1, probability=False, random_state=None, shrinking=True,\n    tol=0.001, verbose=False)\nBest params: {'C': 0.5, 'coef0': -1, 'gamma': 'scale', 'kernel': 'linear'}\nBest score: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Best estimator:\", grid.best_estimator_)\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = grid.best_estimator_\n",
    "best_estimator.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Almost-Pro way\n",
    "\n",
    "La forma pro es la que hace esto mismo y va recogiendo los errores de entrenamiento, de validación y tiene la capacidad de parar el proceso cuando se requiera además de guardar el modelo en local una vez terminado si es mejor que el que había anteriormente y de cargar el modelo anterior y seguir reentrenando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('classifier',\n",
       "                                        RandomForestClassifier(bootstrap=True,\n",
       "                                                               class_weight=None,\n",
       "                                                               criterion='gini',\n",
       "                                                               max_depth=None,\n",
       "                                                               max_features='auto',\n",
       "                                                               max_leaf_nodes=None,\n",
       "                                                               min_impurity_decrease=0.0,\n",
       "                                                               min_impurity_split=None,\n",
       "                                                               min_samples_leaf=1,\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n...\n",
       "                         {'classifier': [SVC(C=1.0, cache_size=200,\n",
       "                                             class_weight=None, coef0=0.0,\n",
       "                                             decision_function_shape='ovr',\n",
       "                                             degree=3, gamma='auto_deprecated',\n",
       "                                             kernel='linear', max_iter=-1,\n",
       "                                             probability=False,\n",
       "                                             random_state=None, shrinking=True,\n",
       "                                             tol=0.001, verbose=False)],\n",
       "                          'classifier__kernel': ['linear', 'rbf', 'sigmoid']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "####### En el GridSearchCV, combinando procesos Pipeline #######\n",
    "pipe = Pipeline(steps=[('classifier',RandomForestClassifier())]) #cada 'steps' es una tupla\n",
    "                                    #¿Por qué se pone aquí 'RandomForestClassifier()'... porque hay no puede estar en 'null'/None... Luego en la iteración de 'hiperparametros' sustituirá por cada 'classifier' de cada 'parameters'\n",
    "\n",
    "logistic_params = {\n",
    "                    'classifier':[LogisticRegression()],\n",
    "                    'classifier__penalty':['l1','l2'],\n",
    "                    'classifier__C': np.arange(0.1,4,0.5)\n",
    "}\n",
    "\n",
    "random_forest_params = {\n",
    "                        'classifier':[RandomForestClassifier()],\n",
    "                        'classifier__n_estimators': [10,100,500,1000],\n",
    "                        'classifier__max_features': [1,2,3]\n",
    "}\n",
    "\n",
    "svc_params = {\n",
    "              'classifier':[SVC()],\n",
    "              'classifier__kernel':['linear','rbf','sigmoid']\n",
    "}\n",
    "\n",
    "search_space = [logistic_params,random_forest_params,svc_params]\n",
    "\n",
    "grid = GridSearchCV(pipe,\n",
    "                    search_space,\n",
    "                    cv=10,\n",
    "                    n_jobs=-1)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best estimator: Pipeline(memory=None,\n         steps=[('classifier',\n                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)\nBest params: {'classifier': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n    kernel='linear', max_iter=-1, probability=False, random_state=None,\n    shrinking=True, tol=0.001, verbose=False), 'classifier__kernel': 'linear'}\nBest score: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Best estimator:\", grid.best_estimator_)\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "best_estimator = grid.best_estimator_\n",
    "best_estimator.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(grid.predict(X_test))\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('classifier',\n",
       "                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                     decision_function_shape='ovr', degree=3,\n",
       "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "grid.best_estimator_['classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_['classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Another way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Declara un par de Pipeline, con 1 sólo modelo, pero incluido otros proceso #######\n",
    "#### A DANIEL EL PROFESOR LE GUSTA MÁS ESTA TERCERA OPCIÓN ##############################\n",
    "\n",
    "reg_log = Pipeline( steps=[\n",
    "                            ('imputer',SimpleImputer()), #imputar missing values\n",
    "                            ('scaler',StandardScaler()), #estandariza\n",
    "                            ('reglog',LogisticRegression()) #Generar\n",
    "]) # 'imputer','scaler','reglog'... son solo identificadores que indico 'yo', puedo poner el nombre que quiera\n",
    "\n",
    "svc = Pipeline( steps=[\n",
    "                        ('scaler',StandardScaler()),\n",
    "                        ('selectkbest',SelectKBest()),\n",
    "                        ('svc', SVC())\n",
    "])\n",
    "\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "re_log_param = {\n",
    "    \"imputer__strategy\": ['mean', 'median', 'most_frequent'],\n",
    "    \"reglog__penalty\": [\"l1\", \"l2\"],\n",
    "    \"reglog__C\": np.arange(0.1, 4, 0.5)\n",
    "}\n",
    "#Se pueden mezclar los hiperparámetros de las operaciones/procesos ... pero NO de modelos.\n",
    "\n",
    "svc_param = {\n",
    "    \"selectkbest__k\": [1, 2, 3],\n",
    "    \"svc__C\": np.arange(0.1, 0.9, 0.1),\n",
    "    \"svc__kernel\": ['linear', 'poly', 'rbf']\n",
    "}\n",
    "\n",
    "rand_forest_params = {\n",
    "    'n_estimators': [10, 100, 500, 1000],\n",
    "    'max_features': [1, 2, 3]\n",
    "}\n",
    "\n",
    "####### Hay que montar un GridSerchCV para cada modelo #######\n",
    "\n",
    "gs_reg_log = GridSearchCV(reg_log,\n",
    "                        re_log_param,\n",
    "                        scoring= 'accuracy',\n",
    "                        cv= 10,\n",
    "                        n_jobs = -1,\n",
    "                        verbose = 1)\n",
    "\n",
    "gs_svc = GridSearchCV(svc,\n",
    "                        svc_param,\n",
    "                        scoring= 'accuracy',\n",
    "                        cv= 10,\n",
    "                        n_jobs = -1,\n",
    "                        verbose = 1)\n",
    "\n",
    "gs_rand_forest = GridSearchCV(random_forest,\n",
    "                            rand_forest_params,\n",
    "                            cv= 10,\n",
    "                             n_jobs = -1,\n",
    "                            verbose = 1)\n",
    "\n",
    "grids = {'gs_reg_log':gs_reg_log,\n",
    "        'gs_svc':gs_svc,\n",
    "        'gs_rand_forest': gs_rand_forest\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "[Parallel(n_jobs=-1)]: Done 116 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "Wall time: 24 s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   19.0s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "####### CODE #######\n",
    "for nombre, grid_searche in  grids.items():\n",
    "    grid_searche.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_items([('gs_reg_log', GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('imputer',\n",
       "                                        SimpleImputer(add_indicator=False,\n",
       "                                                      copy=True,\n",
       "                                                      fill_value=None,\n",
       "                                                      missing_values=nan,\n",
       "                                                      strategy='mean',\n",
       "                                                      verbose=0)),\n",
       "                                       ('scaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('reglog',\n",
       "                                        LogisticRegression(C=1.0,\n",
       "                                                           class_weight=None,\n",
       "                                                           dual=False,\n",
       "                                                           fit_intercept...\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='warn',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'imputer__strategy': ['mean', 'median',\n",
       "                                               'most_frequent'],\n",
       "                         'reglog__C': array([0.1, 0.6, 1.1, 1.6, 2.1, 2.6, 3.1, 3.6]),\n",
       "                         'reglog__penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=1)), ('gs_svc', GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('scaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('selectkbest',\n",
       "                                        SelectKBest(k=10,\n",
       "                                                    score_func=<function f_classif at 0x0000023380A9CAF8>)),\n",
       "                                       ('svc',\n",
       "                                        SVC(C=1.0, cache_size=200,\n",
       "                                            class_weight=None, coef0=0.0,\n",
       "                                            decision_function_shape='ovr',\n",
       "                                            degree=3, gamma='auto...\n",
       "                                            kernel='rbf', max_iter=-1,\n",
       "                                            probability=False,\n",
       "                                            random_state=None, shrinking=True,\n",
       "                                            tol=0.001, verbose=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'selectkbest__k': [1, 2, 3],\n",
       "                         'svc__C': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]),\n",
       "                         'svc__kernel': ['linear', 'poly', 'rbf']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=1)), ('gs_rand_forest', GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_features': [1, 2, 3],\n",
       "                         'n_estimators': [10, 100, 500, 1000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1))])"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "grids.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Grid  Best score\n",
       "1          gs_svc    0.958333\n",
       "0      gs_reg_log    0.941667\n",
       "2  gs_rand_forest    0.941667"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Grid</th>\n      <th>Best score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>gs_svc</td>\n      <td>0.958333</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>gs_reg_log</td>\n      <td>0.941667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>gs_rand_forest</td>\n      <td>0.941667</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "best_grids = [(i, j.best_score_) for i, j in grids.items()]\n",
    "\n",
    "best_grids = pd.DataFrame(best_grids, columns = ['Grid', 'Best score'])\n",
    "best_grids.sort_values(by='Best score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best estimator: Pipeline(memory=None,\n         steps=[('scaler',\n                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n                ('selectkbest',\n                 SelectKBest(k=2,\n                             score_func=<function f_classif at 0x0000023380A9CAF8>)),\n                ('svc',\n                 SVC(C=0.7000000000000001, cache_size=200, class_weight=None,\n                     coef0=0.0, decision_function_shape='ovr', degree=3,\n                     gamma='auto_deprecated', kernel='poly', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)\nBest params: {'selectkbest__k': 2, 'svc__C': 0.7000000000000001, 'svc__kernel': 'poly'}\nBest score: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"Best estimator:\", gs_svc.best_estimator_)\n",
    "print(\"Best params:\", gs_svc.best_params_)\n",
    "print(\"Best score:\", gs_svc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### GUARDAR MODELO PARA LLEGADO EL MOMENTO  ==> SUBIRLO A PRODUCCIÓN #######\n",
    "estimator = gs_svc.best_estimator_\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('finished_model.model','wb') as archivo_salida:\n",
    "    pickle.dump(estimator, archivo_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### CODE #######\n",
    "with open('finished_model.model', 'rb') as archivo_entrada:\n",
    "    pileline_importado = pickle.load(archivo_entrada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('selectkbest',\n",
       "                 SelectKBest(k=2,\n",
       "                             score_func=<function f_classif at 0x0000023380A9CAF8>)),\n",
       "                ('svc',\n",
       "                 SVC(C=0.7000000000000001, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='auto_deprecated', kernel='poly', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "pileline_importado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}